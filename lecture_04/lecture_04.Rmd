# Kinetic Monte Carlo

## Introduction

In our first three lectures, we have explored how Monte Carlo methods can generate representative samples from the Boltzmann distribution, allowing us to calculate equilibrium properties of chemical systems. We have seen how Metropolis Monte Carlo solves the sampling problem by focusing computational effort on the physically relevant regions of configuration space. While Monte Carlo methods excel at estimating time-independent properties&mdash;average energies, structural distributions, and thermodynamic quantities&mdash;they tell us nothing about how systems evolve over time.

Yet many of the most interesting questions in chemistry are inherently time-dependent. How quickly does a protein fold into its native structure? How do atoms diffuse across a catalyst surface? What is the rate-limiting step in a complex reaction mechanism? For these questions, we need not just the equilibrium distribution, but the dynamics of how systems move between states.

To address these time-dependent questions, we turn to Kinetic Monte Carlo (KMC). Unlike Metropolis Monte Carlo, which accepts or rejects moves based on energy differences, KMC selects moves based on the relative rates of possible transitions and associates a physical time with each step. This allows us to follow the dynamical evolution of systems through time, capturing the sequence and timing of events rather than just the average behavior.

## The Memoryless Property: Lightbulbs and Radioactive Nuclei

Let us begin with a thought experiment to illustrate a crucial property of many physical processes:

Imagine we are quality assurance inspectors for a manufacturer of high-quality lightbulbs rated to last 10 years. Part of our job involves annual home inspections to assess the likelihood of bulbs failing in the coming year, replacing any that exceed our risk threshold.

On a typical inspection day, we visit two houses:

- In the first house, the lightbulbs were installed just 2 years ago.
- In the second house, the lightbulbs were installed 12 years ago, already exceeding their 10-year rating.

Which lightbulb would we think is more likely to fail before our next inspection? Most people would say the 12-year-old bulb, and they would be correct&mdash;lightbulbs "age" and become more likely to fail as they get older. For lightbulbs, the failure rate increases with time, a property known as "aging."

Now consider a similar situation with radioactive nuclei:

We are observing two carbon-14 nuclei. Based on its rate constant, we calculate there is a 0.01% chance that a carbon-14 nucleus will decay in the next minute.

A colleague then tells us: "I've been watching one of these nuclei for the past two weeks, and it hasn't decayed yet. The other nucleus was only added to our experiment this morning."

Should we update our probability estimate for either nucleus decaying in the next minute?

The answer is no. Both nuclei still have exactly a 0.01% chance of decaying in the next minute, regardless of how long they have already been observed. Unlike lightbulbs, radioactive nuclei do not "age" or get closer to decaying with time. 

This property&mdash;that future behavior depends only on the current state, not on past history&mdash;defines what mathematicians call a "memoryless" process. For radioactive decay, this means the nucleus has a constant probability of decaying in any small time interval, regardless of how long it has already existed.

## From Memoryless Processes to Exponential Distributions

For memoryless processes like radioactive decay, a fundamental question is: how long will we have to wait until the event (like decay) occurs? This duration is called the "waiting time"&mdash;the time interval between the start of our observation and the occurrence of the event.

For a memoryless process with decay constant (or rate constant) $k$, the waiting time follows an exponential distribution with probability density function (a full derivation is provided in Appendix \@ref(math-deriv)):

$$p_\mathrm{wait}(t) = k\exp(-kt)$$

This distribution has several important implications:

1. **Short waiting times are most likely**: The maximum probability density occurs at $t = 0$. Counterintuitively, the most probable time for the event to occur is right at the start of our observation.

2. **The average waiting time is $1/k$**: For a rate constant of 0.1 s<sup>&minus;1</sup>, the average time until decay is 10 seconds. However, this average emerges from a wide range of possible waiting times.

3. **There is a long tail**: Although short waiting times are most probable, there is always a chance of waiting much longer than the average. Some nuclei decay almost immediately, while others might survive for several multiples of the average lifetime.

4. **The memoryless property appears in the distribution**: At any point in time, the remaining waiting time still follows the same exponential distribution&mdash;the future distribution of waiting times is always the same, regardless of how long we have waited already.

From the waiting time distribution, we can calculate the probability that an event occurs within a specific time interval. The cumulative distribution function (CDF) gives the probability that the event has occurred by time $t$:

$$
\begin{align}
P(t) &= \int_0^t p_\mathrm{wait}(\tau)\,\mathrm{d}\tau \\
     &= \int_0^t k\exp(-k\tau)\,\mathrm{d}\tau \\
     &= 1 - \exp(-kt)
\end{align}
$$

The complementary quantity, called the "survival probability" $S(t)$, gives the probability that the event has not yet occurred by time $t$:

$$
\begin{align}
S(t) &= 1 - P(t) \\
     &= \exp(-kt)
\end{align}
$$

## Two Competing Radioactive Decays

Now let us consider the more complex case of two different radioactive nuclei sitting side by side: a carbon-14 atom with decay constant $k_1$ and a tritium (hydrogen-3) atom with decay constant $k_2$. Both nuclei will eventually decay, but two questions arise: how long will we wait until the first nucleus decays, and which nucleus is likely to decay first?

Let us tackle the first question. For neither nucleus to have decayed by time $t$, both must have survived until that time. Using the survival probability we just derived, and since the nuclei decay independently, the total survival probability is the product of their individual survival probabilities:

$$S_\mathrm{total}(t) = S_1(t) \times S_2(t) = \exp(-k_1t) \times \exp(-k_2t) = \exp(-(k_1 + k_2)t)$$

This is another exponential function, but with rate constant $k_\mathrm{total} = k_1 + k_2$. This means the waiting time until the first decay follows an exponential distribution with average waiting time $1/k_\mathrm{total}$, which is shorter than either nucleus's individual average lifetime.

For example, if carbon-14 has a decay constant of $k_1 = 3.8 \times 10^{-12}$ s<sup>&minus;1</sup> and tritium has $k_2 = 1.8 \times 10^{-9}$ s<sup>&minus;1</sup>, then the average waiting time until one of them decays is:

$$\langle \tau \rangle = \frac{1}{k_1 + k_2} = \frac{1}{3.8 \times 10^{-12} + 1.8 \times 10^{-9}} \approx \frac{1}{1.8 \times 10^{-9}} \approx 5.6 \times 10^8 \text{ seconds}$$

Which is much closer to tritium's half-life than carbon-14's, as we would intuitively expect since tritium decays much faster.

Now for the second question: which nucleus is likely to decay first? The probability that carbon-14 decays first is:

$$P(\text{C-14 decays first}) = \frac{k_1}{k_1 + k_2} = \frac{3.8 \times 10^{-12}}{3.8 \times 10^{-12} + 1.8 \times 10^{-9}} \approx 0.0021$$

While the probability that tritium decays first is:

$$P(\text{tritium decays first}) = \frac{k_2}{k_1 + k_2} \approx 0.9979$$

In other words, the tritium atom is about 474 times more likely to decay first than the carbon-14 atom, which matches our intuition since tritium's rate constant is about 474 times larger (the mathematical proof of this result follows the same integration approach we used for the survival probability).

## Generalizing to Multiple Radioactive Nuclei

The approach we have developed extends to any number of competing decay processes. If we have $N$ different radioactive nuclei with decay constants $k_1, k_2, ..., k_N$, the total decay rate is:

$$k_\mathrm{total} = k_1 + k_2 + ... + k_N = \sum_{i=1}^N k_i$$

The waiting time until the first decay follows an exponential distribution:

$$p(\tau) = k_\mathrm{total} \times \exp(-k_\mathrm{total} \times \tau)$$

And the probability that nucleus $j$ is the one that decays first is:

$$P(\text{nucleus $j$ decays first}) = \frac{k_j}{k_\mathrm{total}}$$

These two principles&mdash;exponentially distributed waiting times with rate $k_\mathrm{total}$ and process selection with probabilities proportional to individual rates&mdash;form the mathematical core of the KMC algorithm.

## Building the KMC Algorithm

### Generating Exponentially Distributed Random Times

With our mathematical foundation in place, we can now build the KMC algorithm. The key insight is that we can use random numbers to generate events that follow exactly the statistical patterns we have derived.

First, how do we generate waiting times that follow an exponential distribution? The trick involves a technique called "inverse transform sampling." Here is how it works:

1. Generate a uniform random number $r$ between 0 and 1
2. Transform it using the inverse of the exponential cumulative distribution function (CDF)

For any exponential distribution with rate parameter $k$ (whether a decay constant or more generally a rate constant), the CDF is:

$$F(\tau) = 1 - \exp(-k \times \tau)$$

To generate a waiting time, we set $F(\tau) = r$ and solve for $\tau$:

$$
\begin{align}
r &= 1 - \exp(-k \times \tau) \\
\exp(-k \times \tau) &= 1 - r \\
\tau &= -\frac{\ln(1 - r)}{k}
\end{align}
$$

Here we can make an important simplification. When we generate a uniform random number $r$ between 0 and 1, the value $(1-r)$ is also a uniform random number between 0 and 1. This is because the uniform distribution between 0 and 1 is symmetric around 0.5. 

To understand this intuitively, imagine generating values between 0 and 1 on a number line:

- If $r = 0.2$, then $(1-r) = 0.8$
- If $r = 0.7$, then $(1-r) = 0.3$
- If $r = 0.01$, then $(1-r) = 0.99$

In each case, the value $(1-r)$ is also uniformly distributed between 0 and 1. The transformation simply "flips" the distribution around 0.5, but since a uniform distribution has equal probability everywhere, the flipped distribution is identical to the original.

Therefore, instead of computing $(1-r)$, we can just use our original random number $r$ directly:

$$\tau = -\frac{\ln(r)}{k}$$

This simplification is common in many Monte Carlo algorithms and makes the implementation more straightforward without changing the statistical properties of the generated waiting times.

### Selecting Which Nucleus Decays

To select which nucleus decays, we use another random number and compare it against the cumulative probabilities of the processes:

1. Generate a uniform random number $s$ between 0 and 1
2. If $s < \frac{k_1}{k_\mathrm{total}}$, select nucleus 1
3. If $\frac{k_1}{k_\mathrm{total}} \leq s < \frac{k_1 + k_2}{k_\mathrm{total}}$, select nucleus 2
4. And so on for additional nuclei

This is equivalent to dividing a line from 0 to 1 into segments proportional to each nucleus's decay probability, then seeing which segment contains our random number.

### The Complete KMC Algorithm

1. **Start with the system in a well-defined state and set time to zero.**

2. **Create a catalog of all possible events and their rates.**
   - For each site or component, determine what events could happen there
   - Calculate the rate constant for each possible event
   - Sum up the rates to get the total rate $k_\mathrm{total}$

3. **Advance time by generating a random waiting time.**
   - Generate a random number $r_1$ uniformly between 0 and 1
   - Calculate $\tau = -\ln(r_1)/k_\mathrm{total}$
   - Advance the simulation clock: $t = t + \tau$

4. **Select which event occurs.**
   - Generate another random number $r_2$ between 0 and 1
   - Use $r_2$ to select an event with probability proportional to its rate
   - A simple approach: if $r_2 < k_1/k_\mathrm{total}$, select event 1; otherwise, if $r_2 < (k_1+k_2)/k_\mathrm{total}$, select event 2; and so on

5. **Execute the selected event and update the system.**
   - Change the system state according to the selected event
   - Update the catalog of possible events and their rates (only those affected by the change)

6. **Repeat steps 2-5** until reaching the desired simulation time or end condition.

The KMC algorithm focuses computational effort on times when events actually occur. Unlike time-step methods that process periods when nothing happens, KMC jumps directly from event to event, making it effective for systems with widely varying timescales.

## A Worked Example: Radioactive Decay Chain

Let us illustrate these concepts by considering a simple example: a radioactive decay chain where A atoms decay to B atoms, which then decay to C atoms:

$$\mathrm{A} \overset{k_1}\longrightarrow \mathrm{B} \overset{k_2}\longrightarrow \mathrm{C}$$

We will start with 10 A atoms and follow the system's evolution using KMC, tracking each atom individually:

1. Each individual $\mathrm{A}$ atom has a chance to decay to $\mathrm{B}$ with rate $k_1$
2. Each individual $\mathrm{B}$ atom has a chance to decay to $\mathrm{C}$ with rate $k_2$

Let us use $k_1 = 1$ s<sup>&minus;1</sup> and $k_2 = 2$ s<sup>&minus;1</sup>, meaning B atoms decay twice as fast as A atoms.

Figure \@ref(fig:kmc-decay-chain) illustrates the first five steps of our KMC simulation, showing how the system evolves and how random numbers determine both the timing of events and which events occur.

```{r kmc-decay-chain, fig.cap="Visual representation of the first five steps in a KMC simulation of the radioactive decay chain A $\\to$ B $\\to$ C. Each row shows: the current state of the system (red circles = A atoms, green circles = B atoms, yellow circles = C atoms); the total event rate divided by event type; the random number $r_1$ used to generate the waiting time $\\Delta t$; the random number $r_2$ used for event selection (with colored bars showing the probability ranges for each possible event); and the selected event.", out.width='100%', fig.align='center'}
knitr::include_graphics("lecture_04/figures/kmc-decay-chain.png")
```

Here are the first five steps in detail:

1. **Initial setup** 
   - Starting state: $N_\mathrm{A} = 10$, $N_\mathrm{B} = 0$, $N_\mathrm{C} = 0$, $t = 0$
   - Total rate: $k_\mathrm{total} = 1 \times 10 + 2 \times 0 = 10$ s<sup>&minus;1</sup>
   - Generate $r_1 = 0.368$ $\to$ waiting time: $\tau = -\ln(0.368)/10 = 0.1$ s
   - Advance time: $t = 0 + 0.1 = 0.1$ s
   - Generate $r_2 = 0.275$
   - Since there is only one possible event type ($\mathrm{A} \to \mathrm{B}$), select that
   - Update: $N_\mathrm{A} = 9$, $N_\mathrm{B} = 1$, $N_\mathrm{C} = 0$

2. **Second iteration** 
   - Total rate: $k_\mathrm{total} = 1 \times 9 + 2 \times 1 = 11$ s<sup>&minus;1</sup>
   - Generate $r_1 = 0.841$ $\to$ waiting time: $\tau = -\ln(0.841)/11 = 0.016$ s
   - Advance time: $t = 0.1 + 0.016 = 0.116$ s
   - Generate $r_2 = 0.682$
   - Compare: $0.682 < (9/11) = 0.818$, so select $\mathrm{A} \to \mathrm{B}$
   - Update: $N_\mathrm{A} = 8$, $N_\mathrm{B} = 2$, $N_\mathrm{C} = 0$

3. **Third iteration** 
   - Total rate: $k_\mathrm{total} = 1 \times 8 + 2 \times 2 = 12$ s<sup>&minus;1</sup>
   - Generate $r_1 = 0.042$ $\to$ waiting time: $\tau = -\ln(0.042)/12 = 0.264$ s
   - Advance time: $t = 0.116 + 0.264 = 0.38$ s
   - Generate $r_2 = 0.058$
   - Compare: $0.058 < (8/12) = 0.667$, so select $\mathrm{A} \to \mathrm{B}$
   - Update: $N_\mathrm{A} = 7$, $N_\mathrm{B} = 3$, $N_\mathrm{C} = 0$

4. **Fourth iteration** 
   - Total rate: $k_\mathrm{total} = 1 \times 7 + 2 \times 3 = 13$ s<sup>&minus;1</sup>
   - Generate $r_1 = 0.194$ $\to$ waiting time: $\tau = -\ln(0.194)/13 = 0.126$ s
   - Advance time: $t = 0.38 + 0.126 = 0.506$ s
   - Generate $r_2 = 0.960$
   - Compare: $0.960 > (7/13) = 0.538$, so select $\mathrm{B} \to \mathrm{C}$
   - Update: $N_\mathrm{A} = 7$, $N_\mathrm{B} = 2$, $N_\mathrm{C} = 1$

5. **Fifth iteration** 
   - Total rate: $k_\mathrm{total} = 1 \times 7 + 2 \times 2 = 11$ s<sup>&minus;1</sup>
   - Generate $r_1 = 0.782$ $\to$ waiting time: $\tau = -\ln(0.782)/11 = 0.022$ s
   - Advance time: $t = 0.506 + 0.022 = 0.528$ s
   - Generate $r_2 = 0.411$
   - Compare: $0.411 < (7/11) = 0.636$, so select $\mathrm{A} \to \mathrm{B}$
   - Update: $N_\mathrm{A} = 6$, $N_\mathrm{B} = 3$, $N_\mathrm{C} = 1$

As the simulation continues beyond these first few steps, we can observe the complete time evolution of all three species. Figure \@ref(fig:kmc-example-10) shows the population dynamics throughout the entire simulation run.

```{r kmc-example-10, fig.cap="Population dynamics in a KMC simulation of the radioactive decay chain A → B → C starting with 10 A atoms. Species A (red) decreases exponentially, species B (green) rises and then falls as an intermediate, and species C (yellow) steadily accumulates as the final product.", out.width='50%', fig.align='center'}
knitr::include_graphics("lecture_04/figures/kmc-example-10.png")
```

This single KMC trajectory reveals the characteristic behavior of a sequential radioactive decay process. Species A diminishes with the approximately exponential decay pattern expected for a first-order process, gradually converting into the intermediate species B. The intermediate exhibits the classic rise-and-fall pattern typical of sequential reactions—initially accumulating as it forms from A, then declining as it transforms into the final product C. Meanwhile, species C steadily accumulates throughout the simulation, eventually becoming the sole remaining species once all transformations are complete.

What makes KMC particularly valuable is evident in the non-smooth progression of the population curves. Unlike deterministic rate equations which produce perfectly smooth trajectories, the KMC simulation captures the inherent stochasticity of the decay process. Each decay event occurs at a randomly determined moment, creating subtle fluctuations in the overall trajectory. If we were to run the simulation multiple times with different random number sequences, each trajectory would show unique variations while maintaining the same overall pattern—an accurate representation of how real radioactive decay processes behave at the microscopic level.

This stochastic approach makes KMC especially suitable for systems with small populations where fluctuations significantly impact the overall behavior, or for processes where rare events play an important role. The method bridges the gap between microscopic randomness and macroscopic behavior, providing insights not available through purely deterministic methods.


## Summary

In this lecture, we have developed the mathematical foundation of Kinetic Monte Carlo and applied it to chemical systems:

1. We started with a thought experiment contrasting aging processes (like lightbulbs) with memoryless processes (like radioactive decay) to introduce the concept of memorylessness
2. We explained how memoryless processes are characterized by exponentially distributed waiting times
3. We analyzed competing processes (multiple radioactive nuclei) and derived both the waiting time distribution and the probabilities for which event occurs first
4. We constructed the KMC algorithm, showing how to generate event times and select events with the correct statistical properties
5. We demonstrated the algorithm with a detailed example of a radioactive decay chain, illustrating the fundamental principles of KMC

KMC provides a powerful framework for simulating time-dependent processes in chemical systems, especially those involving rare events or widely separated time scales. Unlike Metropolis Monte Carlo, which focuses only on equilibrium sampling, KMC gives detailed information about the dynamical evolution of systems.

The method is particularly valuable for surface reactions, diffusion in solids, crystal growth, and other processes where the relevant events are well-defined and separated in time. By focusing computational effort only on the moments when events occur, KMC efficiently bridges the gap between atomistic simulation and macroscopic kinetics.
