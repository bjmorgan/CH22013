<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Lecture 2 Monte Carlo Methods Applied to Chemical Systems | CH22013 Lecture Notes</title>
  <meta name="description" content="These are notes to accompany the 2025 CH22013 lecture course on Monte Carlo methods." />
  <meta name="generator" content="bookdown 0.42 and GitBook 2.6.7" />

  <meta property="og:title" content="Lecture 2 Monte Carlo Methods Applied to Chemical Systems | CH22013 Lecture Notes" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="These are notes to accompany the 2025 CH22013 lecture course on Monte Carlo methods." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Lecture 2 Monte Carlo Methods Applied to Chemical Systems | CH22013 Lecture Notes" />
  
  <meta name="twitter:description" content="These are notes to accompany the 2025 CH22013 lecture course on Monte Carlo methods." />
  

<meta name="author" content="Benjamin J. Morgan" />


<meta name="date" content="2025-03-26" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="monte-carlo-introduction.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">CH22013 Monte Carlo Methods</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About</a></li>
<li class="chapter" data-level="1" data-path="monte-carlo-introduction.html"><a href="monte-carlo-introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction to Monte Carlo Methods</a>
<ul>
<li class="chapter" data-level="1.1" data-path="monte-carlo-introduction.html"><a href="monte-carlo-introduction.html#introduction-to-averaging-sampling"><i class="fa fa-check"></i><b>1.1</b> Introduction to Averaging &amp; Sampling</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="monte-carlo-introduction.html"><a href="monte-carlo-introduction.html#the-statistical-nature-of-chemical-systems"><i class="fa fa-check"></i><b>1.1.1</b> The Statistical Nature of Chemical Systems</a></li>
<li class="chapter" data-level="1.1.2" data-path="monte-carlo-introduction.html"><a href="monte-carlo-introduction.html#probability-distributions"><i class="fa fa-check"></i><b>1.1.2</b> Probability Distributions</a></li>
<li class="chapter" data-level="1.1.3" data-path="monte-carlo-introduction.html"><a href="monte-carlo-introduction.html#the-boltzmann-distribution"><i class="fa fa-check"></i><b>1.1.3</b> The Boltzmann Distribution</a></li>
<li class="chapter" data-level="1.1.4" data-path="monte-carlo-introduction.html"><a href="monte-carlo-introduction.html#the-computational-challenge"><i class="fa fa-check"></i><b>1.1.4</b> The Computational Challenge</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="monte-carlo-introduction.html"><a href="monte-carlo-introduction.html#the-solution-statistical-sampling"><i class="fa fa-check"></i><b>1.2</b> The Solution: Statistical Sampling</a></li>
<li class="chapter" data-level="1.3" data-path="monte-carlo-introduction.html"><a href="monte-carlo-introduction.html#two-approaches-to-sampling"><i class="fa fa-check"></i><b>1.3</b> Two Approaches to Sampling</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="monte-carlo-introduction.html"><a href="monte-carlo-introduction.html#molecular-dynamics-approach"><i class="fa fa-check"></i><b>1.3.1</b> Molecular Dynamics Approach</a></li>
<li class="chapter" data-level="1.3.2" data-path="monte-carlo-introduction.html"><a href="monte-carlo-introduction.html#monte-carlo-approach"><i class="fa fa-check"></i><b>1.3.2</b> Monte Carlo Approach</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="monte-carlo-introduction.html"><a href="monte-carlo-introduction.html#fundamental-monte-carlo-examples"><i class="fa fa-check"></i><b>1.4</b> Fundamental Monte Carlo Examples</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="monte-carlo-introduction.html"><a href="monte-carlo-introduction.html#estimating-π-by-monte-carlo-integration"><i class="fa fa-check"></i><b>1.4.1</b> Estimating π by Monte Carlo Integration</a></li>
<li class="chapter" data-level="1.4.2" data-path="monte-carlo-introduction.html"><a href="monte-carlo-introduction.html#function-averaging-and-numerical-integration"><i class="fa fa-check"></i><b>1.4.2</b> Function Averaging and Numerical Integration</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="monte-carlo-introduction.html"><a href="monte-carlo-introduction.html#statistical-uncertainty-in-monte-carlo-methods"><i class="fa fa-check"></i><b>1.5</b> Statistical Uncertainty in Monte Carlo Methods</a></li>
<li class="chapter" data-level="1.6" data-path="monte-carlo-introduction.html"><a href="monte-carlo-introduction.html#summary-and-preview"><i class="fa fa-check"></i><b>1.6</b> Summary and Preview</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="monte-carlo-introduction.html"><a href="monte-carlo-introduction.html#key-takeaways-from-lecture-1"><i class="fa fa-check"></i><b>1.6.1</b> Key Takeaways from Lecture 1</a></li>
<li class="chapter" data-level="1.6.2" data-path="monte-carlo-introduction.html"><a href="monte-carlo-introduction.html#looking-ahead-to-lecture-2"><i class="fa fa-check"></i><b>1.6.2</b> Looking Ahead to Lecture 2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="monte-carlo-chemical.html"><a href="monte-carlo-chemical.html"><i class="fa fa-check"></i><b>2</b> Monte Carlo Methods Applied to Chemical Systems</a>
<ul>
<li class="chapter" data-level="2.1" data-path="monte-carlo-chemical.html"><a href="monte-carlo-chemical.html#introduction-to-non-uniform-sampling"><i class="fa fa-check"></i><b>2.1</b> Introduction to Non-Uniform Sampling</a></li>
<li class="chapter" data-level="2.2" data-path="monte-carlo-chemical.html"><a href="monte-carlo-chemical.html#boltzmann-sampling-and-the-inefficiency-of-uniform-sampling"><i class="fa fa-check"></i><b>2.2</b> Boltzmann Sampling and the Inefficiency of Uniform Sampling</a></li>
<li class="chapter" data-level="2.3" data-path="monte-carlo-chemical.html"><a href="monte-carlo-chemical.html#the-solution-markov-chain-monte-carlo"><i class="fa fa-check"></i><b>2.3</b> The Solution: Markov Chain Monte Carlo</a></li>
<li class="chapter" data-level="2.4" data-path="monte-carlo-chemical.html"><a href="monte-carlo-chemical.html#what-is-a-markov-chain"><i class="fa fa-check"></i><b>2.4</b> What is a Markov Chain?</a></li>
<li class="chapter" data-level="2.5" data-path="monte-carlo-chemical.html"><a href="monte-carlo-chemical.html#the-principle-of-detailed-balance"><i class="fa fa-check"></i><b>2.5</b> The Principle of Detailed Balance</a></li>
<li class="chapter" data-level="2.6" data-path="monte-carlo-chemical.html"><a href="monte-carlo-chemical.html#the-metropolis-algorithm"><i class="fa fa-check"></i><b>2.6</b> The Metropolis Algorithm</a></li>
<li class="chapter" data-level="2.7" data-path="monte-carlo-chemical.html"><a href="monte-carlo-chemical.html#the-metropolis-monte-carlo-algorithm-in-practice"><i class="fa fa-check"></i><b>2.7</b> The Metropolis Monte Carlo Algorithm in Practice</a></li>
<li class="chapter" data-level="2.8" data-path="monte-carlo-chemical.html"><a href="monte-carlo-chemical.html#why-we-record-rejected-moves-in-metropolis-monte-carlo"><i class="fa fa-check"></i><b>2.8</b> Why We Record Rejected Moves in Metropolis Monte Carlo</a>
<ul>
<li class="chapter" data-level="2.8.1" data-path="monte-carlo-chemical.html"><a href="monte-carlo-chemical.html#the-fundamental-principle"><i class="fa fa-check"></i><b>2.8.1</b> The Fundamental Principle</a></li>
<li class="chapter" data-level="2.8.2" data-path="monte-carlo-chemical.html"><a href="monte-carlo-chemical.html#two-state-system-example"><i class="fa fa-check"></i><b>2.8.2</b> Two-State System Example</a></li>
<li class="chapter" data-level="2.8.3" data-path="monte-carlo-chemical.html"><a href="monte-carlo-chemical.html#markov-chain-perspective"><i class="fa fa-check"></i><b>2.8.3</b> Markov Chain Perspective</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="monte-carlo-chemical.html"><a href="monte-carlo-chemical.html#example-4-spin-ising-model"><i class="fa fa-check"></i><b>2.9</b> Example: 4-Spin Ising Model</a></li>
<li class="chapter" data-level="2.10" data-path="monte-carlo-chemical.html"><a href="monte-carlo-chemical.html#summary"><i class="fa fa-check"></i><b>2.10</b> Summary</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">CH22013 Lecture Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="monte-carlo-chemical" class="section level1 hasAnchor" number="2">
<h1><span class="header-section-number">Lecture 2</span> Monte Carlo Methods Applied to Chemical Systems<a href="monte-carlo-chemical.html#monte-carlo-chemical" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="introduction-to-non-uniform-sampling" class="section level2 hasAnchor" number="2.1">
<h2><span class="header-section-number">2.1</span> Introduction to Non-Uniform Sampling<a href="monte-carlo-chemical.html#introduction-to-non-uniform-sampling" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The previous lecture introduced the general idea behind Monte Carlo methods: using repeated random sampling to obtain numerical results.
In the first lecture, we focussed on the problem of calculating some property <span class="math inline">\(A\)</span> as an average over a large set of states.</p>
<p>Recall from the first lecture that for any property A, its true average value is calculated as a sum over all possible states:</p>
<p><span class="math display">\[
\langle A \rangle = \sum_i A_i \times P_i
\]</span></p>
<p>Where <span class="math inline">\(A_i\)</span> is the value of property A in state i, and <span class="math inline">\(P_i\)</span> is the probability of state <span class="math inline">\(i\)</span> occurring. In many problems of this type, evaluating this sum exactly is impossible due to the existence of an enormous number of states.
Monte Carlo methods allow us to estimate <span class="math inline">\(\langle A \rangle\)</span> by sampling a subset of randomly chosen states.</p>
<p>In the examples in Lecture <a href="monte-carlo-introduction.html#monte-carlo-introduction">1</a>, we used uniform sampling—where each possible location in our sample space has an equal probability of being selected. In these examples, uniform sampling was effective because it allowed us to efficiently explore the regions of sample space relevant to the property we were estimating.</p>
<p>For chemical systems at equilibrium, however, uniform sampling is highly inefficient, frequently to the extent of being computationally intractable, and we instead use non-uniform sampling to more efficiently estimate <span class="math inline">\(\langle A \rangle\)</span>.</p>
</div>
<div id="boltzmann-sampling-and-the-inefficiency-of-uniform-sampling" class="section level2 hasAnchor" number="2.2">
<h2><span class="header-section-number">2.2</span> Boltzmann Sampling and the Inefficiency of Uniform Sampling<a href="monte-carlo-chemical.html#boltzmann-sampling-and-the-inefficiency-of-uniform-sampling" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>For chemical systems at equilibrium, states are distributed according to the Boltzmann distribution:</p>
<p><span class="math display">\[
P(\mathbf{r}) = \frac{\exp(-U(\mathbf{r})/kT)}{Z}
\]</span></p>
<p>Where the partition function <span class="math inline">\(Z\)</span> is:</p>
<p><span class="math display">\[
Z = \sum \exp(-U(\mathbf{r})/kT)
\]</span></p>
<p>If we were to sample uniformly, we might initially propose estimating <span class="math inline">\(\langle A \rangle\)</span> via:</p>
<p><span class="math display">\[
\langle A \rangle \approx \frac{1}{Z} \sum_{i=1}^N A(r_i) \exp(-U(r_i)/kT)
\]</span></p>
<p>However, this approach requires knowing <span class="math inline">\(Z\)</span>, which we typically cannot compute directly as it involves summing over all possible states—the very challenge we’re using Monte Carlo to overcome.</p>
<p>Fortunately, we can construct an alternative estimator that doesn’t require prior knowledge of <span class="math inline">\(Z\)</span>:</p>
<p><span class="math display">\[
\langle A \rangle \approx \frac{\sum_{i=1}^N A(r_i) \exp(-U(r_i)/kT)}{\sum_{i=1}^N \exp(-U(r_i)/kT)}
\]</span></p>
<p>The denominator effectively estimates <span class="math inline">\(Z\)</span> from our samples, allowing us to compute averages without knowing <span class="math inline">\(Z\)</span> in advance.</p>
<p>Even with this improved estimator, uniform sampling remains highly inefficient for chemical systems. The Boltzmann factor decreases exponentially as energy increases, meaning any property <span class="math inline">\(\langle A \rangle\)</span> is dominated by contributions from a relatively small number of low-energy states. The vast majority of possible states have high energies with negligible Boltzmann weights, yet these states occupy most of the configuration space.</p>
<p>Consider a molecular system with <span class="math inline">\(N\)</span> atoms (<span class="math inline">\(3N\)</span> spatial degrees of freedom). In a system with just 10 atoms, uniform sampling would predominantly generate configurations with atoms positioned unphysically close to each other. These high-energy configurations have effectively zero Boltzmann weights, contributing nothing to our estimate of <span class="math inline">\(\langle A \rangle\)</span>. However, uniform sampling spends nearly all of its time generating these irrelevant states, resulting in extremely slow convergence.</p>
<p>This inefficiency worsens exponentially with system size. Each additional degree of freedom further reduces the already tiny fraction of configuration space containing physically relevant states. For most chemical systems of interest, uniform sampling becomes computationally unfeasible.</p>
<p>We need an alternative approach—a method that preferentially samples the low-energy regions that dominate the Boltzmann distribution. This is the central focus of this lecture.</p>
</div>
<div id="the-solution-markov-chain-monte-carlo" class="section level2 hasAnchor" number="2.3">
<h2><span class="header-section-number">2.3</span> The Solution: Markov Chain Monte Carlo<a href="monte-carlo-chemical.html#the-solution-markov-chain-monte-carlo" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In Lecture 1, we discussed estimating the average height of people in Britain by measuring a representative sample. Let’s revisit this example to illustrate the challenge of sampling from a complex distribution.</p>
<p>If we attempted uniform geographical sampling—randomly selecting 100m × 100m squares on a map of Britain and measuring everyone within each selected square—we would encounter severe inefficiency. Most selected squares would contain few or no people (falling on rural areas, forests, mountains, or bodies of water), while densely populated urban areas would be underrepresented. We would waste most of our sampling effort on empty regions while gathering insufficient data from cities and towns, where the majority of people live.</p>
<p>This mirrors our problem in chemical systems: uniform sampling of configuration space predominantly generates high-energy states with negligible Boltzmann weights, while the physically relevant low-energy states occupy only a tiny fraction of the total space.</p>
<p>A more efficient approach to our height-measuring problem would be to design a sampling process that naturally visits locations with frequency proportional to their population density. Imagine a “random walker” traversing the UK, who:</p>
<ol style="list-style-type: decimal">
<li>Spends most time in cities and towns</li>
<li>Occasionally visits villages and small settlements</li>
<li>Rarely ventures into uninhabited areas</li>
</ol>
<p>This walker would measure the height of individuals encountered during the journey. The crucial insight is that if our walker visits each location with probability <em>exactly proportional</em> to the number of people there, then each person in the UK has an equal chance of being included in our sample. This means we can calculate a simple, unweighted average of the measured heights without any correction factors.</p>
<p>This is precisely the approach of Markov Chain Monte Carlo (MCMC) methods. Instead of generating independent random samples with uniform probability, we create a “chain” of samples where each new sample is generated based on the current one. The chain is designed to visit states with frequency proportional to their probability in the target distribution—in our case, the Boltzmann distribution.</p>
<p>When our sampling frequency matches the Boltzmann distribution, we can calculate thermodynamic properties using simple averaging:</p>
<p><span class="math display">\[
\langle A \rangle \approx \frac{1}{N} \sum_{i=1}^N A(\mathbf{r}_i)
\]</span></p>
<p>Where configurations <span class="math inline">\(\mathbf{r}_i\)</span> are selected with frequency proportional to <span class="math inline">\(\exp(-U(\mathbf{r}_i)/kT)\)</span>.</p>
<p>The challenge now becomes designing a sampling process that naturally visits configurations with frequencies matching their Boltzmann probabilities, without requiring prior knowledge of the full energy landscape. This is where the mathematics of Markov chains provides the solution.</p>
</div>
<div id="what-is-a-markov-chain" class="section level2 hasAnchor" number="2.4">
<h2><span class="header-section-number">2.4</span> What is a Markov Chain?<a href="monte-carlo-chemical.html#what-is-a-markov-chain" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The tool we need for sampling according to the Boltzmann distribution is called a “Markov chain.”</p>
<p>At its core, a Markov chain is a sequence of states where each new state emerges from the current one through a probabilistic process. For a simple example, consider a weather model where tomorrow’s weather depends only on today’s weather: if it’s sunny today, there might be a 70% chance of sun tomorrow and 30% chance of rain; if it’s raining today, there might be a 60% chance of continued rain and 40% chance of sun tomorrow.</p>
<p>The defining characteristic of a Markov chain is its “memoryless” property—the next state depends only on the current state, not on the history of previous states. In our weather example, this means that if it’s sunny today, the probability of sun tomorrow is 70% regardless of whether yesterday was sunny or rainy. This property is particularly useful for our sampling problem because it allows us to design a step-by-step process that explores configuration space efficiently without needing to track the entire history of the simulation.</p>
<p>Mathematically, for systems with discrete states, we describe a Markov chain through transition probabilities—the chances of moving from one state to another in a single step. These probabilities form a transition matrix where each entry <span class="math inline">\(P(i\to j)\)</span> represents the probability of moving from state <span class="math inline">\(i\)</span> to state <span class="math inline">\(j\)</span>. For our simple weather example, we could represent these as:</p>
<pre><code>              Tomorrow
              Sunny  Rainy
Today  Sunny   0.7    0.3
       Rainy   0.4    0.6</code></pre>
<p>For systems with many possible states, such as molecular configurations, these transition probabilities dictate how the simulation moves through configuration space.</p>
<p>Markov chains that are irreducible (can reach any state from any other state) and aperiodic (don’t cycle deterministically) eventually reach an equilibrium distribution. At equilibrium, the probability of finding the system in each state stabilizes to a constant value, even as the system continues to move between states. This stable probability distribution is called the “stationary distribution” of the chain.</p>
<p>For our sampling purpose, we need to design a Markov chain whose stationary distribution matches exactly the Boltzmann distribution. If we achieve this, then after running the chain for sufficient steps, the frequency with which we visit each configuration will naturally match its Boltzmann probability—solving our sampling problem.</p>
</div>
<div id="the-principle-of-detailed-balance" class="section level2 hasAnchor" number="2.5">
<h2><span class="header-section-number">2.5</span> The Principle of Detailed Balance<a href="monte-carlo-chemical.html#the-principle-of-detailed-balance" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>At equilibrium in any Markov chain, the probability of finding the system in each state remains constant over time. This means that for each state, the total probability flow into that state must equal the total flow out—a condition known as “global balance.”</p>
<p>One way to satisfy global balance is to require a stronger condition called “detailed balance.” Detailed balance requires that for each pair of states i and j, the probability flow from i to j exactly equals the probability flow from j back to i:</p>
<p><span class="math display">\[
\pi(i) \times P(i \to j) = \pi(j) \times P(j \to i)
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(\pi(i)\)</span> is the equilibrium probability of state <span class="math inline">\(i\)</span> in our desired stationary distribution</li>
<li><span class="math inline">\(P(i \to j)\)</span> is the transition probability from state <span class="math inline">\(i\)</span> to state <span class="math inline">\(j\)</span></li>
</ul>
<p>This equation has a straightforward interpretation: at equilibrium, the rate of transitions from <span class="math inline">\(i\)</span> to <span class="math inline">\(j\)</span> must exactly balance the rate of transitions from <span class="math inline">\(j\)</span> back to <span class="math inline">\(i\)</span>. This microscopic reversibility ensures that the overall population of each state remains constant.</p>
<p>For our application to chemical systems, we want <span class="math inline">\(\pi(i)\)</span> to be the Boltzmann probability. Substituting the Boltzmann distribution into the detailed balance equation:</p>
<p><span class="math display">\[
\exp(-U(i)/kT) \times P(i \to j) = \exp(-U(j)/kT) \times P(j \to i)
\]</span></p>
<p>Rearranging to isolate the ratio of transition probabilities:</p>
<p><span class="math display">\[
\frac{P(i \to j)}{P(j \to i)} = \frac{\exp(-U(j)/kT)}{\exp(-U(i)/kT)} = \exp(-(U(j)-U(i))/kT)
\]</span></p>
<p>This equation provides a crucial constraint: any Markov chain with transition probabilities satisfying this relationship will have the Boltzmann distribution as its stationary distribution. The ratio of forward and backward transition probabilities must equal the exponential of the negative energy difference divided by kT.</p>
<p>Note that this equation does not fully specify the transition probabilities—it only constrains their ratio. This flexibility allows us to design various algorithms that satisfy detailed balance while being computationally efficient.</p>
</div>
<div id="the-metropolis-algorithm" class="section level2 hasAnchor" number="2.6">
<h2><span class="header-section-number">2.6</span> The Metropolis Algorithm<a href="monte-carlo-chemical.html#the-metropolis-algorithm" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In 1953, Nicholas Metropolis and colleagues published an algorithm that provides a simple and powerful way to satisfy detailed balance. Their approach has become a cornerstone of computational chemistry and physics.</p>
<p>The key insight of the Metropolis method is to separate the transition probability into two parts:</p>
<p><span class="math display">\[
P(i \to j) = \alpha(i \to j) \times \text{acc}(i \to j)
\]</span></p>
<p>Where <span class="math inline">\(\alpha(i \to j)\)</span> is the proposal probability—the likelihood of suggesting a move from configuration <span class="math inline">\(i\)</span> to configuration <span class="math inline">\(j\)</span>—and <span class="math inline">\(\text{acc}(i \to j)\)</span> is the acceptance probability—the likelihood of accepting that proposed move.</p>
<p>The simplest approach is to use symmetric proposal probabilities where <span class="math inline">\(\alpha(i \to j) = \alpha(j \to i)\)</span>. This might involve, for example, randomly displacing an atom in any direction with equal probability. With this simplification, our detailed balance condition becomes:</p>
<p><span class="math display">\[
\frac{\text{acc}(i \to j)}{\text{acc}(j \to i)} = \exp(-(U(j)-U(i))/kT)
\]</span></p>
<p>The Metropolis solution to this equation is:</p>
<p><span class="math display">\[
\text{acc}(i \to j) = \min(1, \exp(-(U(j)-U(i))/kT))
\]</span></p>
<p>This formula tells us that:</p>
<ul>
<li>If the proposed move decreases the energy (<span class="math inline">\(U(j) &lt; U(i)\)</span>), accept it with probability 1 (always)</li>
<li>If the proposed move increases the energy, accept it with probability <span class="math inline">\(\exp(-(U(j)-U(i))/kT)\)</span></li>
</ul>
<p>The key property of this acceptance rule is that it mathematically guarantees sampling states according to their Boltzmann probabilities. When a simulation uses this acceptance criterion, it will generate configurations with frequencies proportional to <span class="math inline">\(\exp(-U/kT)\)</span>, provided the Markov chain can reach all relevant states. This is the efficient sampling method we need to focus computational effort on the physically relevant low-energy regions of configuration space.</p>
</div>
<div id="the-metropolis-monte-carlo-algorithm-in-practice" class="section level2 hasAnchor" number="2.7">
<h2><span class="header-section-number">2.7</span> The Metropolis Monte Carlo Algorithm in Practice<a href="monte-carlo-chemical.html#the-metropolis-monte-carlo-algorithm-in-practice" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Let’s now translate the Metropolis acceptance criterion into a complete computational procedure. This practical algorithm provides a step-by-step framework for implementing Monte Carlo simulations across a range of chemical systems.</p>
<p>The Metropolis Monte Carlo algorithm consists of the following steps that work together to generate a sequence of configurations sampled according to the Boltzmann distribution:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Initialization</strong>: Begin with an initial configuration of your system. This might be a random arrangement, a regular lattice, or a known low-energy structure.</p></li>
<li><p><strong>Energy calculation</strong>: Calculate the energy of this initial configuration <span class="math inline">\(U(\mathbf{r})\)</span> using an appropriate potential energy function for your system.</p></li>
<li><p><strong>Move proposal</strong>: Propose a move to a new configuration <span class="math inline">\(\mathbf{r}&#39;\)</span>. The nature of this move depends on your system—it might involve displacing an atom, rotating a dihedral angle, flipping a spin, or other modifications appropriate to the degrees of freedom being studied.</p></li>
<li><p><strong>Energy evaluation</strong>: Calculate the energy of the proposed configuration <span class="math inline">\(U(\mathbf{r}&#39;)\)</span>.</p></li>
<li><p><strong>Energy difference</strong>: Compute the energy change that would result from this move: <span class="math inline">\(\Delta U = U(\mathbf{r}&#39;) - U(\mathbf{r})\)</span>.</p></li>
<li><p><strong>Acceptance decision</strong>: Apply the Metropolis criterion to decide whether to accept the proposed move:</p>
<ul>
<li>If <span class="math inline">\(\Delta U \leq 0\)</span> (energy decreases or remains the same), accept the move.</li>
<li>If <span class="math inline">\(\Delta U &gt; 0\)</span> (energy increases), generate a random number <span class="math inline">\(\xi\)</span> between 0 and 1.
<ul>
<li>If <span class="math inline">\(\xi &lt; \exp(-\Delta U/kT)\)</span>, accept the move.</li>
<li>Otherwise, reject the move.</li>
</ul></li>
</ul></li>
<li><p><strong>Configuration update</strong>: If the move is accepted, update your current configuration to <span class="math inline">\(\mathbf{r}&#39;\)</span>. If rejected, retain the original configuration <span class="math inline">\(\mathbf{r}\)</span>.</p></li>
<li><p><strong>Property calculation</strong>: Calculate any properties of interest for the current configuration. These might include energies, structural parameters, or other observable quantities.</p></li>
<li><p><strong>Iteration</strong>: Return to step 3 and repeat the process many times to explore configuration space thoroughly.</p></li>
<li><p><strong>Analysis</strong>: After generating a sufficient number of configurations, compute averages of your calculated properties to estimate thermodynamic observables.</p></li>
</ol>
<p>This procedure embodies two important features of the Metropolis method:</p>
<ol style="list-style-type: decimal">
<li>It samples configurations according to their Boltzmann weights. After an initial equilibration period, the generated configurations properly represent the equilibrium distribution, reproducing complex thermodynamic behavior through simple local decisions.</li>
<li>It applies universally across different types of systems. The same algorithm works for atomic systems, molecular simulations, spin models, or lattice systems, with only the move types and energy functions changing.</li>
</ol>
<p>These properties make the Metropolis Monte Carlo method a versatile and powerful tool for computational studies of equilibrium systems.</p>
</div>
<div id="why-we-record-rejected-moves-in-metropolis-monte-carlo" class="section level2 hasAnchor" number="2.8">
<h2><span class="header-section-number">2.8</span> Why We Record Rejected Moves in Metropolis Monte Carlo<a href="monte-carlo-chemical.html#why-we-record-rejected-moves-in-metropolis-monte-carlo" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>When implementing the Metropolis algorithm, we include the current state in our statistics again when a proposed move is rejected. This aspect of the algorithm is sometimes confusing to newcomers, but it’s essential for correct sampling of the Boltzmann distribution.</p>
<div id="the-fundamental-principle" class="section level3 hasAnchor" number="2.8.1">
<h3><span class="header-section-number">2.8.1</span> The Fundamental Principle<a href="monte-carlo-chemical.html#the-fundamental-principle" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Our goal is to generate configurations with frequencies proportional to their Boltzmann weights. When we reject a move, we’re effectively saying that the current state should be counted again in our statistics. This repetition ensures that lower-energy states are sampled more frequently than higher-energy states, in accordance with their higher Boltzmann probabilities.</p>
</div>
<div id="two-state-system-example" class="section level3 hasAnchor" number="2.8.2">
<h3><span class="header-section-number">2.8.2</span> Two-State System Example<a href="monte-carlo-chemical.html#two-state-system-example" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consider a simple system with just two possible states: state 1 with energy <span class="math inline">\(E_1\)</span> and state 2 with energy <span class="math inline">\(E_2\)</span>, where <span class="math inline">\(E_2 &gt; E_1\)</span>. According to the Boltzmann distribution, the ratio of probabilities should be:</p>
<p><span class="math display">\[\frac{P(2)}{P(1)} = \exp\left(-\frac{E_2 - E_1}{kT}\right)\]</span></p>
<p>This ratio varies with temperature—at high temperatures it approaches 1, and at low temperatures it approaches 0.</p>
<p>If we incorrectly record states only after accepted moves, our simulation would always alternate between states 1 and 2, giving equal sampling regardless of temperature. This contradicts the Boltzmann distribution, which requires state 1 to be increasingly favored as temperature decreases.</p>
</div>
<div id="markov-chain-perspective" class="section level3 hasAnchor" number="2.8.3">
<h3><span class="header-section-number">2.8.3</span> Markov Chain Perspective<a href="monte-carlo-chemical.html#markov-chain-perspective" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>This can be understood from the mathematics of Markov chains. For a 2-state system, the transition matrix is:</p>
<pre><code>           To state 1  To state 2
From state 1    $P(1\to1)$    $P(1\to2)$
From state 2    $P(2\to1)$    $P(2\to2)$</code></pre>
<p>In a correct Metropolis implementation:</p>
<ul>
<li><span class="math inline">\(P(1\to2) = \min(1, \exp(-(E_2-E_1)/kT))\)</span>, which is less than 1 when <span class="math inline">\(E_2 &gt; E_1\)</span></li>
<li><span class="math inline">\(P(1\to1) = 1 - P(1\to2)\)</span>, which is non-zero (representing rejected moves)</li>
<li><span class="math inline">\(P(2\to1) = 1\)</span> (always accept moves that lower energy)</li>
<li><span class="math inline">\(P(2\to2) = 0\)</span></li>
</ul>
<p>If we only recorded accepted moves, we’d effectively use a modified transition matrix that produces a uniform distribution, not the Boltzmann distribution.</p>
<p>The correct implementation is to record a state after every attempted move:
- If the move is accepted, record the new state
- If the move is rejected, record the current state again</p>
<p>At low temperatures, this means we’ll record state 1 many times in a row (multiple rejections), occasionally recording state 2, which quickly transitions back to state 1. This produces statistics with state 1 appearing much more frequently than state 2, correctly reflecting the Boltzmann distribution.</p>
</div>
</div>
<div id="example-4-spin-ising-model" class="section level2 hasAnchor" number="2.9">
<h2><span class="header-section-number">2.9</span> Example: 4-Spin Ising Model<a href="monte-carlo-chemical.html#example-4-spin-ising-model" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Let’s examine how the Metropolis algorithm works in practice with a simple example: a one-dimensional Ising model with four spins arranged in a ring (with periodic boundary conditions). Each spin can point either up (+1) or down (−1), interacting only with its nearest neighbors, as illustrated in Figure <a href="monte-carlo-chemical.html#fig:fig-ising-ring">2.1</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:fig-ising-ring"></span>
<img src="lecture_02/figures/ising-ring.png" alt="A 4-spin Ising model with periodic boundary conditions. Each spin can point up (+1) or down (&amp;minus;1) and interacts with its two neighboring spins." width="20%" />
<p class="caption">
Figure 2.1: A 4-spin Ising model with periodic boundary conditions. Each spin can point up (+1) or down (−1) and interacts with its two neighboring spins.
</p>
</div>
<p>The energy of this system is given by:</p>
<p><span class="math display">\[
H(\sigma) = -\sum_{\langle i,j \rangle} J_{ij} \sigma_i \sigma_j
\]</span></p>
<p>Where the sum runs over adjacent pairs of spins, with J representing the interaction strength. For ferromagnetic coupling (J &gt; 0), parallel spins have lower energy than antiparallel ones.</p>
<p>With just four spins, we have only <span class="math inline">\(2^4 = 16\)</span> possible configurations. These configurations fall into three energy levels, as shown in Figure <a href="monte-carlo-chemical.html#fig:fig-ising-configs">2.2</a>:</p>
<ul>
<li>Highest energy (<span class="math inline">\(+4J\)</span>): Alternating up and down spins (antiferromagnetic). Two configurations with <span class="math inline">\(|m| = 0\)</span>.</li>
<li>Intermediate energy (<span class="math inline">\(0J\)</span>): Twelve configurations with mixed spin alignments.</li>
<li>Ground state (<span class="math inline">\(-4J\)</span>): All spins aligned (either all up or all down — ferromagnetic). Two configurations with magnitude of magnetization <span class="math inline">\(|m| = 4\)</span>.</li>
</ul>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:fig-ising-configs"></span>
<img src="lecture_02/figures/ising-configs.png" alt="All 16 possible spin configurations for a 4-spin Ising model, showing energy values and magnetization values." width="100%%" />
<p class="caption">
Figure 2.2: All 16 possible spin configurations for a 4-spin Ising model, showing energy values and magnetization values.
</p>
</div>
<p>A Metropolis Monte Carlo simulation of this system works as follows:</p>
<ol style="list-style-type: decimal">
<li>Start with a random arrangement of the four spins.</li>
<li>At each step, randomly select one spin and propose flipping it.</li>
<li>Calculate the energy change <span class="math inline">\(\Delta E\)</span> that would result from this flip.</li>
<li>Apply the Metropolis criterion: accept the flip if <span class="math inline">\(\Delta E \leq 0\)</span>; otherwise accept with probability <span class="math inline">\(\exp(-\Delta E/kT)\)</span>.</li>
<li>Record the new configuration (or repeat the current one if the move was rejected).</li>
</ol>
<p>Figure <a href="monte-carlo-chemical.html#fig:fig-mc-trajectory">2.3</a> illustrates a portion of a Monte Carlo trajectory, showing how the system evolves through a sequence of configurations by accepting or rejecting proposed spin flips. Notice how the system tends to spend more time in lower-energy states, yet occasionally accepts moves to higher-energy states, allowing it to explore the full configuration space.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:fig-mc-trajectory"></span>
<img src="lecture_02/figures/mc-trajectory.png" alt="A portion of a Monte Carlo trajectory showing how the system evolves through a sequence of configurations. Each row shows the current spin state, the proposed move (highlighting the spin flipped in this move), the energy change for the proposed move, and the probability of the move being accepted. For proposed moves that would increase the total energy, i.e., $P_\mathrm{acc} &lt; 1$, the table also shows the random number generated. Finally the table records whether the proposed move was accepted or rejected." width="100%" />
<p class="caption">
Figure 2.3: A portion of a Monte Carlo trajectory showing how the system evolves through a sequence of configurations. Each row shows the current spin state, the proposed move (highlighting the spin flipped in this move), the energy change for the proposed move, and the probability of the move being accepted. For proposed moves that would increase the total energy, i.e., <span class="math inline">\(P_\mathrm{acc} &lt; 1\)</span>, the table also shows the random number generated. Finally the table records whether the proposed move was accepted or rejected.
</p>
</div>
<p>After an initial equilibration period, the Metropolis algorithm ensures that the frequency with which we sample each state matches its Boltzmann probability. This means we can calculate thermodynamic properties by simply averaging over our collected samples. For instance, calculating the average magnetization magnitude <span class="math inline">\(\langle |M| \rangle\)</span> is straightforward—we average the magnetization magnitudes from our sampled configurations:</p>
<p><span class="math display">\[
\langle |M| \rangle \approx \frac{1}{N} \sum_{i=1}^N |M|_i
\]</span></p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:fig-temp-dependence"></span>
<img src="lecture_02/figures/temp-dependence.png" alt="Temperature dependence of average absolute magnetization in the 4-spin Ising model. The graph shows both the exact solution (solid line) and Monte Carlo results (points), with the high-temperature limit of 1.5 indicated." width="55%" />
<p class="caption">
Figure 2.4: Temperature dependence of average absolute magnetization in the 4-spin Ising model. The graph shows both the exact solution (solid line) and Monte Carlo results (points), with the high-temperature limit of 1.5 indicated.
</p>
</div>
<p>Figure <a href="monte-carlo-chemical.html#fig:fig-temp-dependence">2.4</a> shows how temperature affects this system by plotting the average magnetization magnitude across a range of temperatures. At very low temperatures, the system remains “frozen” in one of the ground states with all spins aligned, giving <span class="math inline">\(\langle |M| \rangle = 4\)</span>. As temperature increases, thermal fluctuations allow higher-energy configurations to be sampled, and the average magnetization decreases, eventually approaching the high-temperature limit of <span class="math inline">\(\langle |M| \rangle = 1.5\)</span> where all configurations become equally probable.</p>
<p>A key strength of the Monte Carlo method is that the procedure remains the same regardless of system size. For this 4-spin system, we have <span class="math inline">\(2^4 = 16\)</span> total states, and we can evaluate <span class="math inline">\(\langle |M| \rangle\)</span> by direct enumeration. However, for larger systems, direct enumeration quickly becomes impossible: a 100-spin system has <span class="math inline">\(2^{100} \approx 1.27 \times 10^{30}\)</span> states! Yet the Monte Carlo procedure remains exactly the same—we still select and flip individual spins, evaluate energy changes, and apply the Metropolis criterion. Through this local sampling process, the method efficiently explores the states with significant Boltzmann weights without requiring exhaustive enumeration.</p>
</div>
<div id="summary" class="section level2 hasAnchor" number="2.10">
<h2><span class="header-section-number">2.10</span> Summary<a href="monte-carlo-chemical.html#summary" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this lecture, we’ve expanded our Monte Carlo toolkit to address the challenges of chemical systems. We’ve seen why the Boltzmann distribution requires specialized sampling techniques, and how the Metropolis algorithm provides an elegant solution through Markov Chain Monte Carlo.</p>
<p>The key concepts we’ve covered include:</p>
<ul>
<li>The fundamental inefficiency of uniform sampling for chemical systems</li>
<li>The Boltzmann distribution and the exponential relationship between energy and probability</li>
<li>How Markov chains generate samples from complex probability distributions</li>
<li>The principle of detailed balance as a mathematical foundation for correct sampling</li>
<li>The Metropolis acceptance criterion and its practical implementation</li>
<li>A worked example using the 4-spin Ising model to demonstrate these principles</li>
</ul>
<p>The Metropolis Monte Carlo algorithm efficiently focuses computational efforts on the low-energy regions that dominate Boltzmann-weighted averages without requiring exhaustive enumeration of the vast configuration space. This makes the method valuable for systems where direct calculation is prohibitive.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="monte-carlo-introduction.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": "https://github.com/bjmorgan/CH22013/main/lecture_02/lecture_02.Rmd",
    "text": "Edit"
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "section"
  },
  "mathjax": {
    "extensions": "mhchem.js"
  },
  "mathjax_config": {
    "TeX": {
      "Macros": {
        "conc": [
          "[\mathrm{#1}]",
          1
        ],
        "diffc": [
          "\frac{\mathrm{d}\conc{#1}}{\mathrm{d}t}",
          1
        ]
      }
    }
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
