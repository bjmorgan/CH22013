[["index.html", "CH22013 Lecture Notes About", " CH22013 Lecture Notes Benjamin J. Morgan 2025-04-01 About These notes accompany the 2025 CH22013 lecture course on Monte Carlo methods. "],["monte-carlo-introduction.html", "Lecture 1 Introduction to Monte Carlo Methods 1.1 Introduction to Averaging &amp; Sampling 1.2 The Solution: Statistical Sampling 1.3 Two Approaches to Sampling 1.4 Fundamental Monte Carlo Examples 1.5 Statistical Uncertainty in Monte Carlo Methods 1.6 Summary and Preview", " Lecture 1 Introduction to Monte Carlo Methods 1.1 Introduction to Averaging &amp; Sampling Chemistry is fundamentally a statistical science. Macroscopic properties such as pressure, temperature, and heat capacity emerge from the collective behavior of approximately \\(10^{23}\\) atoms or molecules. These observable quantities represent averages over an immense number of microscopic states. A central challenge in computational chemistry is how to accurately estimate these macroscopic properties without having to evaluate every possible molecular arrangement. 1.1.1 The Statistical Nature of Chemical Systems When we measure properties of chemical systems in the laboratory, we observe the average behavior of countless molecules over the duration of our measurement. Even the simplest systems—gases, liquids, or solids—involve enormous numbers of possible arrangements of atoms, with molecules constantly moving, rotating, and vibrating at finite temperatures. To accurately predict these macroscopic measurements, we need to account for this diversity of molecular configurations. Ideally, we would calculate our property of interest for every possible configuration, weight each result by the probability of that configuration occurring, and then sum these weighted values. The mathematical expression for this average is: \\[\\begin{equation} \\langle A \\rangle = \\sum A(\\mathbf{r}) \\times P(\\mathbf{r}) \\end{equation}\\] Where \\(\\mathbf{r}\\) represents a particular configuration of the system, and \\(P(\\mathbf{r})\\) is the probability of finding the system in that configuration. 1.1.2 Probability Distributions \\(P(\\mathbf{r})\\) represents a probability distribution, which describes the likelihood of finding the system in each possible configuration. Probability distributions form the mathematical foundation for describing systems with inherent variability. Probability distributions come in two forms: Discrete distributions apply when a variable can only take specific, countable values. For these, we use a probability mass function (PMF) that gives the probability of each possible outcome. For example, when rolling a fair six-sided die, each number (1—6) has a probability of 1/6. Another example is counting heads in four coin flips, which follows a binomial distribution where the probability of \\(k\\) heads is \\(\\binom{4}{k} \\times (1/2)^4\\). Continuous distributions apply when a variable can take any value within a continuous range. These use a probability density function (PDF) where the probability of finding the variable in a specific range equals the area under the PDF curve over that range. A simple example is a random point selected along a line segment from 0 to 1, which follows a uniform continuous distribution with constant probability density. In all probability distributions, the total probability must equal 1, meaning the system must exist in some state. The average (expected value) of any property A is calculated by weighting each possible value by its probability and summing over all possibilities—exactly the formula we saw earlier for chemical systems. 1.1.3 The Boltzmann Distribution In chemical systems, the probability distribution that governs molecular configurations is the Boltzmann distribution: \\[\\begin{equation} P(\\mathbf{r}) \\propto \\exp(-U(\\mathbf{r})/kT) \\end{equation}\\] Here, \\(U(\\mathbf{r})\\) is the potential energy of configuration \\(\\mathbf{r}\\), \\(k\\) is Boltzmann’s constant, and \\(T\\) is the temperature. This relationship reveals a fundamental principle in physical chemistry: lower-energy configurations are exponentially more probable than higher-energy ones. At room temperature (298 K), a configuration that is just 6 kJ/mol higher in energy is approximately 10 times less probable than the minimum energy state. Temperature determines how strongly the system favors low-energy states—at high temperatures, the distribution becomes more uniform, while at low temperatures, the system is increasingly restricted to the lowest energy states. To create a valid probability distribution, the probabilities must sum to 1: \\[\\begin{equation} \\sum_i P(\\mathbf{r}) = 1 \\end{equation}\\] We achieve this by including a normalization constant, \\(Z\\): \\[\\begin{equation} P(\\mathbf{r}) = \\frac{\\exp(-U(\\mathbf{r})/kT)}{Z} \\end{equation}\\] This constant \\(Z\\) is called the “partition function,” defined as: \\[\\begin{equation} Z = \\sum \\exp(-U(\\mathbf{r})/kT) \\end{equation}\\] The partition function plays a central role in statistical mechanics and thermodynamics, connecting microscopic configurations to macroscopic properties. 1.1.4 The Computational Challenge Let’s revisit our fundamental problem. To calculate the thermodynamic average of a property A, we need to evaluate: \\[\\begin{equation} \\langle A \\rangle = \\sum A(\\mathbf{r}) \\times P(\\mathbf{r}) \\end{equation}\\] Where \\(P(\\mathbf{r})\\) is the Boltzmann distribution: \\[\\begin{equation} P(\\mathbf{r}) = \\frac{\\exp(-U(\\mathbf{r})/kT)}{Z} \\end{equation}\\] A direct approach to this calculation would require: 1. Generating all possible configurations of our system 2. Computing the property A and energy for each configuration 3. Calculating the weighted sum The obstacle lies in the sheer number of possible configurations for any realistic chemical system. Consider a simple example: a \\(10 \\times 10\\) array of surface sites where we want to model the adsorption of 50 molecules. This system has approximately \\(10^{29}\\) possible configurations—more than the number of stars in the observable universe. Direct enumeration becomes impossible. For most chemical systems, the situation is even more extreme. A small protein in solution might have millions of relevant conformations. A metal catalyst with multiple reaction pathways or a polymer chain sampling different spatial arrangements presents an effectively infinite configuration space. This combinatorial explosion makes direct evaluation computationally intractable—even the most powerful supercomputers cannot handle such calculations. 1.2 The Solution: Statistical Sampling Rather than calculating the exact sum, which we’ve established is computationally intractable, we can estimate it through sampling—selecting a subset of configurations that represent the full distribution, evaluating our property of interest for these samples, and calculating their average. This concept of sampling is fundamental throughout science and statistics. Consider estimating the average height of people in Britain. Measuring everyone’s height is impractical, but we can measure a representative sample and use that sample’s average as an estimate of the true population average. The key requirement is that our sample must be representative—it should reflect the true probability distribution of the property we’re measuring. For instance, sampling players arriving for a basketball tournament would likely produce a significant overestimate of the average British height, as basketball players tend to be taller than the general population. In contrast, measuring the heights of people passing by on a street corner on a Saturday afternoon would provide a more representative sample of the British population. When we sample directly from the correct probability distribution (for example, by randomly selecting British citizens with equal probability), we can use simple averaging without additional weighting factors. However, if our sampling method is biased (like measuring only basketball players), we would need to apply appropriate weighting corrections. This principle applies to chemical systems as well. If we could generate configurations directly according to the Boltzmann distribution, calculating thermodynamic properties would simply require averaging the property values: \\[\\begin{equation} \\langle A \\rangle \\approx \\frac{1}{N} \\sum_{i=1}^{N} A(\\mathbf{r}_i) \\end{equation}\\] Where the configurations \\(\\mathbf{r}_i\\) are selected with probability proportional to \\(\\exp(-U(\\mathbf{r}_i)/kT)\\). 1.3 Two Approaches to Sampling Two principal methods have been developed to address the sampling challenge in computational chemistry: 1.3.1 Molecular Dynamics Approach Molecular Dynamics (MD) simulates atomic motion according to Newton’s laws. By following these physical trajectories, MD can sample configurations according to their Boltzmann probabilities. When a simulation trajectory visits a suitably representative set of configurations in the relevant regions of configuration space, the time average provides a good approximation of the desired ensemble average: \\[\\begin{equation} \\langle A \\rangle \\approx \\frac{1}{M} \\sum_{i=1}^{M} A(\\mathbf{r}_i) \\end{equation}\\] Where \\(M\\) is the number of time steps. However, the effectiveness of MD sampling depends on the system’s energy landscape. Consider a protein folding example: if high energy barriers separate different conformational states, the protein may remain trapped in one conformation for the entire simulation duration. The resulting time average would reflect only a small subset of the relevant configuration space, not the true equilibrium ensemble. Timescales present another challenge. Many important chemical processes occur on microsecond to second timescales, while individual MD time steps typically represent femtoseconds. This creates a fundamental gap between simulation capability and the time needed to observe certain phenomena. For instance, studying a slow conformational change or a rare reaction event may require prohibitively long simulation times. Additionally, some systems inherently resist treatment via continuous dynamics. Lattice models with discrete site occupancies, magnetic materials with fixed spin orientations, or any problem where variables can only take discrete values often require different sampling approaches altogether. 1.3.2 Monte Carlo Approach Monte Carlo (MC) methods, named after the famous casino district in Monaco, use random numbers to estimate complex averages through sampling. This approach offers a powerful alternative to Molecular Dynamics for calculating equilibrium properties. In its simplest form, Monte Carlo sampling involves generating configurations using random numbers, evaluating the property of interest for each configuration, and computing the average of these values. 1.4 Fundamental Monte Carlo Examples Before addressing the sampling challenges in chemical systems, let’s examine two classic examples that illustrate the power of Monte Carlo methods with uniform sampling. These examples demonstrate the core principles using simple problems where each possible outcome has an equal probability of occurring. 1.4.1 Estimating π by Monte Carlo Integration One of the simplest demonstrations of Monte Carlo methods is estimating the value of \\(\\pi\\). Consider a circle with radius 1 inscribed inside a square with side length 2. The area of the circle is \\(\\pi\\), while the area of the square is 4. Therefore, the ratio of these areas is \\(\\pi/4\\). We can estimate this ratio by randomly placing points within the square and counting what fraction fall inside the circle. The procedure involves generating \\(N\\) random points with coordinates \\((x,y)\\), where \\(x\\) and \\(y\\) are uniformly distributed between −1 and 1. We then count how many points \\(M\\) satisfy \\(x^2 + y^2 \\leq 1\\), which indicates they fall within the circle. The estimate for \\(\\pi\\) is given by: \\(\\pi \\approx 4 \\times M/N\\). This approach demonstrates how random sampling can solve a deterministic problem. 1.4.2 Function Averaging and Numerical Integration Our second example involves calculating the average value of a function over a specific interval. Consider finding the average value of \\(\\sin^2(x)\\) over the interval \\([0,\\pi]\\). Mathematically, this average is defined as: \\[\\begin{equation} \\text{Average value} = \\frac{1}{\\pi} \\times \\int_0^{\\pi} \\sin^2(x) dx \\end{equation}\\] The analytical solution to this integral is 1/2. Using Monte Carlo methods, we can estimate this average by generating uniform random \\(x\\)-values between 0 and \\(\\pi\\), calculating \\(\\sin^2(x)\\) for each point, and then averaging these results. This procedure can be generalized to estimate any definite integral: \\[\\begin{equation} \\int_a^b f(x) dx \\approx (b-a) \\times \\frac{1}{N} \\sum_{i=1}^{N} f(x_i) \\end{equation}\\] Where \\(x_1\\), \\(x_2\\), …, \\(x_n\\) are uniform random numbers between \\(a\\) and \\(b\\). The strength of this approach becomes apparent when dealing with multi-dimensional integrals, where traditional numerical methods become exponentially more expensive as dimensionality increases. 1.5 Statistical Uncertainty in Monte Carlo Methods A fundamental characteristic of all Monte Carlo methods is that they produce estimates rather than exact answers. Each time we run a Monte Carlo simulation with a different sequence of random numbers, we get a slightly different result. This variation is the source of statistical uncertainty in Monte Carlo methods. Unlike deterministic methods, which might have errors from approximations but give the same answer every time, Monte Carlo methods produce different answers on different runs. This inherent variability means we must consider Monte Carlo results as estimates with associated uncertainty. The precision of these estimates improves as we increase the number of samples. Statistical uncertainty decreases proportionally to \\(1/\\sqrt{N}\\), where \\(N\\) is the number of random samples. To reduce the uncertainty by half, we need to use four times as many samples. This scaling behavior is characteristic of random sampling methods and remains independent of the dimensionality of the problem—a significant advantage in high-dimensional applications. When reporting results from Monte Carlo simulations, it is essential to always include the associated uncertainties alongside the estimated values. This practice is a fundamental aspect of scientific reporting in computational chemistry and allows others to properly evaluate the reliability of the results. 1.6 Summary and Preview 1.6.1 Key Takeaways from Lecture 1 Monte Carlo methods provide powerful tools for estimating averages in complex systems through statistical sampling. We’ve explored: The basic principles of random sampling How Monte Carlo techniques can be applied to mathematical problems The inherent statistical uncertainty in Monte Carlo results and how it decreases with sample size The examples in this lecture have all used uniform sampling—where each possible outcome has an equal probability of being selected. This approach works well for many mathematical problems, including certain numerical integration tasks and geometrical probability calculations. 1.6.2 Looking Ahead to Lecture 2 In the next lecture, we’ll extend Monte Carlo methods to chemical systems, which present additional challenges. We’ll explore how to sample molecular configurations according to the Boltzmann distribution introduced earlier, allowing us to calculate thermodynamic properties of realistic chemical systems. The Metropolis algorithm will provide a solution to the challenge of sampling from the Boltzmann distribution without knowing the partition function. This method has become a cornerstone in computational chemistry, enabling Monte Carlo simulations across a wide range of applications. "],["monte-carlo-chemical.html", "Lecture 2 Monte Carlo Methods Applied to Chemical Systems 2.1 Introduction to Non-Uniform Sampling 2.2 Boltzmann Sampling and the Inefficiency of Uniform Sampling 2.3 The Solution: Markov Chain Monte Carlo 2.4 What is a Markov Chain? 2.5 Summary and Preview", " Lecture 2 Monte Carlo Methods Applied to Chemical Systems 2.1 Introduction to Non-Uniform Sampling The 1\">previous lecture introduced the general idea behind Monte Carlo methods: using repeated random sampling to obtain numerical results. In the first lecture, we focussed on the problem of calculating some property \\(A\\) as an average over a large set of states. Recall from the first lecture that for any property A, its true average value is calculated as a sum over all possible states: \\[ \\langle A \\rangle = \\sum_i A_i \\times P_i \\] Where \\(A_i\\) is the value of property A in state \\(i\\), and \\(P_i\\) is the probability of state \\(i\\) occurring. In many problems of this type, evaluating this sum exactly is impossible due to the existence of an enormous number of states. Monte Carlo methods allow us to estimate \\(\\langle A \\rangle\\) by sampling a subset of randomly chosen states. In the examples in Lecture 1, we used uniform sampling—where each possible location in our sample space has an equal probability of being selected. In these examples, uniform sampling was effective because it allowed us to efficiently explore the regions of sample space relevant to the property we were estimating. For chemical systems at equilibrium, however, uniform sampling is highly inefficient, frequently to the extent of being computationally intractable, and we instead use non-uniform sampling to more efficiently estimate \\(\\langle A \\rangle\\). 2.2 Boltzmann Sampling and the Inefficiency of Uniform Sampling For chemical systems at equilibrium, states are distributed according to the Boltzmann distribution: \\[ P(\\mathbf{r}) = \\frac{\\exp(-U(\\mathbf{r})/kT)}{Z} \\] Where the partition function \\(Z\\) is: \\[ Z = \\sum \\exp(-U(\\mathbf{r})/kT) \\] If we were to sample uniformly, we might initially propose estimating \\(\\langle A \\rangle\\) via: \\[ \\langle A \\rangle \\approx \\frac{1}{Z} \\sum_{i=1}^N A(r_i) \\exp(-U(r_i)/kT) \\] However, this approach requires knowing \\(Z\\), which we typically cannot compute directly as it involves summing over all possible states—the very challenge we’re using Monte Carlo to overcome. Fortunately, we can construct an alternative estimator that doesn’t require prior knowledge of \\(Z\\): \\[ \\langle A \\rangle \\approx \\frac{\\sum_{i=1}^N A(r_i) \\exp(-U(r_i)/kT)}{\\sum_{i=1}^N \\exp(-U(r_i)/kT)} \\] The denominator effectively estimates \\(Z\\) from our samples, allowing us to compute averages without knowing \\(Z\\) in advance. Even with this improved estimator, uniform sampling remains highly inefficient for chemical systems. The Boltzmann factor decreases exponentially as energy increases, meaning any property \\(\\langle A \\rangle\\) is dominated by contributions from a relatively small number of low-energy states. The vast majority of possible states have high energies with negligible Boltzmann weights, yet these states occupy most of the configuration space. Consider a molecular system with \\(N\\) atoms (\\(3N\\) spatial degrees of freedom). In a system with just 10 atoms, uniform sampling would predominantly generate configurations with atoms positioned unphysically close to each other. These high-energy configurations have effectively zero Boltzmann weights, contributing nothing to our estimate of \\(\\langle A \\rangle\\). However, uniform sampling spends nearly all of its time generating these irrelevant states, resulting in extremely slow convergence. This inefficiency worsens exponentially with system size. Each additional degree of freedom further reduces the already tiny fraction of configuration space containing physically relevant states. For most chemical systems of interest, uniform sampling becomes computationally unfeasible. We need an alternative approach—a method that preferentially samples the low-energy regions that dominate the Boltzmann distribution. This is the central focus of this lecture. 2.3 The Solution: Markov Chain Monte Carlo In Lecture 1, we discussed estimating the average height of people in Britain by measuring a representative sample. Let’s revisit this example to illustrate the challenge of sampling from a complex distribution. If we attempted uniform geographical sampling—randomly selecting 100m × 100m squares on a map of Britain and measuring everyone within each selected square—we would encounter severe inefficiency. Most selected squares would contain few or no people (falling on rural areas, forests, mountains, or bodies of water), while densely populated urban areas would be underrepresented. We would waste most of our sampling effort on empty regions while gathering insufficient data from cities and towns, where the majority of people live. This mirrors our problem in chemical systems: uniform sampling of configuration space predominantly generates high-energy states with negligible Boltzmann weights, while the physically relevant low-energy states occupy only a tiny fraction of the total space. A more efficient approach to our height-measuring problem would be to design a sampling process that naturally visits locations with frequency proportional to their population density. Imagine a “random walker” traversing the UK, who: Spends most time in cities and towns Occasionally visits villages and small settlements Rarely ventures into uninhabited areas This walker would measure the height of individuals encountered during the journey. The crucial insight is that if our walker visits each location with probability exactly proportional to the number of people there, then each person in the UK has an equal chance of being included in our sample. This means we can calculate a simple, unweighted average of the measured heights without any correction factors. This is precisely the approach of Markov Chain Monte Carlo (MCMC) methods. Instead of generating independent random samples with uniform probability, we create a “chain” of samples where each new sample is generated based on the current one. The chain is designed to visit states with frequency proportional to their probability in the target distribution—in our case, the Boltzmann distribution. When our sampling frequency matches the Boltzmann distribution, we can calculate thermodynamic properties using simple averaging: \\[ \\langle A \\rangle \\approx \\frac{1}{N} \\sum_{i=1}^N A(\\mathbf{r}_i) \\] Where configurations \\(\\mathbf{r}_i\\) are selected with frequency proportional to \\(\\exp(-U(\\mathbf{r}_i)/kT)\\). The challenge now becomes designing a sampling process that naturally visits configurations with frequencies matching their Boltzmann probabilities, without requiring prior knowledge of the full energy landscape. This is where the mathematics of Markov chains provides the solution. 2.4 What is a Markov Chain? The tool we need for sampling according to the Boltzmann distribution is called a “Markov chain.” At its core, a Markov chain is a sequence of states where each new state emerges from the current one through a probabilistic process. For a simple example, consider a weather model where tomorrow’s weather depends only on today’s weather: if it’s sunny today, there might be a 70% chance of sun tomorrow and 30% chance of rain; if it’s raining today, there might be a 60% chance of continued rain and 40% chance of sun tomorrow. The defining characteristic of a Markov chain is its “memoryless” property—the next state depends only on the current state, not on the history of previous states. In our weather example, this means that if it’s sunny today, the probability of sun tomorrow is 70% regardless of whether yesterday was sunny or rainy. This property is particularly useful for our sampling problem because it allows us to design a step-by-step process that explores configuration space efficiently without needing to track the entire history of the simulation. Mathematically, for systems with discrete states, we describe a Markov chain through transition probabilities—the chances of moving from one state to another in a single step. These probabilities form a transition matrix where each entry \\(P(i\\to j)\\) represents the probability of moving from state \\(i\\) to state \\(j\\). For our simple weather example, we could represent these as: Today Sunny Rainy Tomorrow Sunny 0.7 0.4 Rainy 0.3 0.6 This transition matrix follows what mathematicians call the “column-stochastic” convention. Each column corresponds to a particular starting state, and the entries within that column tell us the probabilities of transitioning to each possible next state. Since these transitions represent all possibilities, the probabilities in each column must sum to 1.1 For systems with many possible states, such as molecular configurations, these transition probabilities dictate how the simulation moves through configuration space. Markov chains that are irreducible (can reach any state from any other state) and aperiodic (don’t cycle deterministically) eventually reach an equilibrium distribution. At equilibrium, the probability of finding the system in each state stabilizes to a constant value, even as the system continues to move between states. This stable probability distribution is called the “stationary distribution” of the chain.2 For our sampling purpose, we need to design a Markov chain whose stationary distribution matches exactly the Boltzmann distribution. If we achieve this, then after running the chain for sufficient steps, the frequency with which we visit each configuration will naturally match its Boltzmann probability—solving our sampling problem. 2.5 Summary and Preview In this lecture, we’ve introduced the concept of non-uniform sampling for chemical systems and identified why uniform sampling is inefficient for these applications. We’ve explored how the Boltzmann distribution governs the probability of states in chemical systems at equilibrium, and we’ve seen how this creates a challenge for computational sampling. The key concepts we’ve covered include: The fundamental inefficiency of uniform sampling for chemical systems The Boltzmann distribution and the exponential relationship between energy and probability The importance of focusing our sampling on low-energy regions of configuration space The concept of Markov Chain Monte Carlo as a solution to our sampling problem The basic properties and mathematics of Markov chains We’ve developed an intuitive understanding of Markov chain sampling using the analogy of a random walker traveling through the UK to measure heights, showing how properly constructed random walks can efficiently sample from complex distributions. In the next lecture, we’ll build on this foundation to explore the specific mathematical conditions required for a Markov chain to sample from the Boltzmann distribution. We’ll introduce the principle of detailed balance and show how the Metropolis algorithm provides a practical implementation that allows efficient sampling of chemical systems. This will lead us to a complete algorithm for Metropolis Monte Carlo that can be applied to a wide range of systems in computational chemistry. For students interested in the mathematical perspective: in the column-stochastic convention, we can represent the state of the system as a probability vector \\(p\\) where each entry gives the probability of being in a particular state. If \\(p_\\mathrm{current}\\) is the current state distribution, then \\(p_\\mathrm{new} = P\\cdot p_\\mathrm{current}\\) gives the probability distribution after one step of the Markov chain, using standard matrix-vector multiplication. Transition matrices can alternatively be represented in row-stochastic form, where each row (rather than column) sums to 1 and represents the probability distribution of transitions from a particular state. In that case, state vectors are row vectors and matrix operations are performed as \\(p_\\mathrm{new} = p_\\mathrm{current}\\cdot P\\).↩︎ From a mathematical perspective, the stationary distribution \\(\\pi\\) of a Markov chain is a probability distribution that remains unchanged after application of the transition matrix. In the column-stochastic convention, this means \\(\\pi = P\\cdot\\pi\\), which is an eigenvalue equation of the form \\(Ax = \\lambda x\\) where \\(\\lambda = 1\\). In other words, the stationary distribution is the eigenvector of the transition matrix \\(P\\) corresponding to the eigenvalue 1.↩︎ "],["metropolis-monte-carlo.html", "Lecture 3 Metropolis Monte Carlo 3.1 Introduction 3.2 Detailed Balance 3.3 The Metropolis Algorithm 3.4 The Metropolis Monte Carlo Algorithm in Practice 3.5 Why We Record Rejected Moves in Metropolis Monte Carlo 3.6 Example: 4-Spin Ising Model 3.7 Example: Butane Conformations 3.8 Equilibration and Sampling 3.9 Temperature Effects and Sampling Challenges 3.10 The Ergodic Hypothesis 3.11 Summary", " Lecture 3 Metropolis Monte Carlo 3.1 Introduction In the previous lecture, we considered the problem of effective sampling of chemical systems. Uniform sampling predominantly generates high-energy configurations with negligible Boltzmann weights, while the low-energy states that contribute the most to thermodynamic averages occupy only a tiny fraction of configuration space. For even modestly sized molecules, most possible configurations have energies so high that they effectively make zero contribution to ensemble averages. As a first step to addressing this problem, we considered the approach of generating a sequence of samples, where each new configuration is obtained from the previous one by making a relatively small, local change. The idea is that if we start in a high-probability region of configuration space, making small local moves will tend to keep us in other high-probability regions, avoiding the unphysical structures that dominate most of configuration space. This sequential sampling approach is mathematically formalized through Markov chains, which provide a framework for generating stochastic paths through configuration space. A crucial property of Markov chains is that, when properly constructed, they eventually reach a stationary distribution—the frequency with which they visit different states stabilizes to a consistent pattern. If we can design Markov chains with the Boltzmann distribution as their stationary distribution, our simulations will naturally sample molecular configurations according to their physical probabilities, allowing us to compute thermodynamic averages through simple averaging.3 The focus of this lecture is how to construct such a Markov chain. 3.2 Detailed Balance At equilibrium in any Markov chain, the probability of finding the system in each state remains constant over time. This means that for each state, the total probability flow into that state must equal the total flow out—a condition known as “global balance.” One way to satisfy global balance is to require a stronger condition called “detailed balance.” Detailed balance requires that for each pair of states \\(i\\) and \\(j\\), the probability flow from \\(i\\) to \\(j\\) exactly equals the probability flow from \\(j\\) back to \\(i\\): \\[ \\pi_i \\times P(i \\to j) = \\pi_j \\times P(j \\to i) \\] Where: \\(\\pi_i\\) is the equilibrium probability of state \\(i\\) in our desired stationary distribution \\(P(i \\to j)\\) is the transition probability from state \\(i\\) to state \\(j\\) This equation has a straightforward interpretation: at equilibrium, the rate of transitions from \\(i\\) to \\(j\\) must exactly balance the rate of transitions from \\(j\\) back to \\(i\\). This microscopic reversibility ensures that the overall population of each state remains constant. For our application to chemical systems, we want \\(\\pi_i\\) to be the Boltzmann probability. Substituting the Boltzmann distribution into the detailed balance equation: \\[ \\exp(-U_i/kT) \\times P(i \\to j) = \\exp(-U_j/kT) \\times P(j \\to i) \\] Rearranging to isolate the ratio of transition probabilities: \\[ \\frac{P(i \\to j)}{P(j \\to i)} = \\frac{\\exp(-U_j/kT)}{\\exp(-U_i/kT)} = \\exp(-(U_j-U_i)/kT) \\] This equation provides a crucial constraint: any Markov chain with transition probabilities satisfying this relationship will have the Boltzmann distribution as its stationary distribution. Note that this equation does not fully specify the transition probabilities—it only constrains their ratio. This flexibility allows us to design various algorithms that satisfy detailed balance while being computationally efficient. 3.3 The Metropolis Algorithm In 1953, Nicholas Metropolis and colleagues published an algorithm that provides a simple and powerful way to satisfy detailed balance. Their approach has become a cornerstone of computational chemistry and physics. The key insight of the Metropolis method is to separate the transition probability into two parts: \\[ P(i \\to j) = \\alpha(i \\to j) \\times \\text{acc}(i \\to j) \\] Where \\(\\alpha(i \\to j)\\) is the proposal probability—the likelihood of suggesting a move from configuration \\(i\\) to configuration \\(j\\)—and \\(\\text{acc}(i \\to j)\\) is the acceptance probability—the likelihood of accepting that proposed move. The simplest approach is to use symmetric proposal probabilities where \\(\\alpha(i \\to j) = \\alpha(j \\to i)\\). This might involve, for example, randomly displacing an atom in any direction with equal probability. With this simplification, our detailed balance condition becomes: \\[ \\frac{\\text{acc}(i \\to j)}{\\text{acc}(j \\to i)} = \\exp(-(U_j-U_i)/kT) \\] The Metropolis solution to this equation is: \\[ \\text{acc}(i \\to j) = \\min(1, \\exp(-(U_j-U_i)/kT)) \\] This formula tells us that: If the proposed move decreases the energy (\\(U_j &lt; U_i\\)), accept it with probability 1 (always) If the proposed move increases the energy, accept it with probability \\(\\exp(-(U_j-U_i)/kT)\\) The key property of this acceptance rule is that it guarantees sampling states according to their Boltzmann probabilities. When a simulation uses this acceptance criterion, it will generate configurations with frequencies proportional to \\(\\exp(-U/kT)\\), provided the Markov chain can reach all relevant states. This is the efficient sampling method we need to focus computational effort on the physically relevant low-energy regions of configuration space. 3.4 The Metropolis Monte Carlo Algorithm in Practice Let’s now translate the Metropolis acceptance criterion into a complete practical algorithm that can be used to implement Monte Carlo simulations of chemical systems. The Metropolis Monte Carlo algorithm consists of the following steps: Initialisation: Begin with an initial configuration of your system. This might be a random arrangement, a regular lattice, or a known low-energy structure. Energy calculation: Calculate the energy of this initial configuration \\(U(\\mathbf{r})\\) using an appropriate potential energy function for your system. Move proposal: Propose a move to a new configuration \\(\\mathbf{r}&#39;\\). The nature of this move depends on your system—it might involve displacing an atom, rotating a dihedral angle, flipping a spin, or other modifications appropriate to the degrees of freedom being studied. Energy evaluation: Calculate the energy of the proposed configuration \\(U(\\mathbf{r}&#39;)\\). Energy difference: Compute the energy change that would result from this move: \\(\\Delta U = U(\\mathbf{r}&#39;) - U(\\mathbf{r})\\). Acceptance decision: Apply the Metropolis criterion to decide whether to accept the proposed move: If \\(\\Delta U \\leq 0\\) (energy decreases or remains the same), accept the move. If \\(\\Delta U &gt; 0\\) (energy increases), generate a random number \\(\\xi\\) between 0 and 1. If \\(\\xi &lt; \\exp(-\\Delta U/kT)\\), accept the move. Otherwise, reject the move. Configuration update: If the move is accepted, update your current configuration to \\(\\mathbf{r}&#39;\\). If rejected, retain the original configuration \\(\\mathbf{r}\\). Property calculation: Calculate any properties of interest for the current configuration (even if the proposed move was not accepted). Iteration: Return to step 3 and repeat the process many times to explore configuration space thoroughly. Analysis: After generating a sufficient number of configurations, compute averages of your calculated properties to estimate thermodynamic observables. 3.5 Why We Record Rejected Moves in Metropolis Monte Carlo A key aspect of the Metropolis algorithm is that we include the current state in our statistics again when a proposed move is rejected. This feature is sometimes confusing, but it’s essential for correct sampling of the Boltzmann distribution. 3.5.1 The Core Principle Our goal is to generate configurations with frequencies proportional to their Boltzmann weights. When we reject a move, we must count the current state again in our statistics. By counting a low-energy state multiple times (when moves away from it are rejected), we ensure that lower-energy states appear more frequently in our sample, correctly reflecting their higher Boltzmann probabilities. 3.5.2 Two-State System Example Consider a simple system with just two possible states: state \\(1\\) with energy \\(E_1\\) and state \\(2\\) with energy \\(E_2\\), where \\(E_2 &gt; E_1\\). According to the Boltzmann distribution, the ratio of probabilities should be: \\[\\frac{P(2)}{P(1)} = \\exp\\left(-\\frac{E_2 - E_1}{kT}\\right)\\] This ratio varies with temperature—at high temperatures it approaches \\(1\\), and at low temperatures it approaches \\(0\\). If we incorrectly record states only after accepted moves, our simulation would always alternate between states \\(1\\) and \\(2\\), giving equal sampling of both states regardless of temperature. This contradicts the Boltzmann distribution, which requires state \\(1\\) to be increasingly favored as temperature decreases. 3.6 Example: 4-Spin Ising Model Let us examine how the Metropolis algorithm works in practice with a simple example: a one-dimensional Ising model with four spins arranged in a ring (with periodic boundary conditions). Each spin can point either up (+1) or down (−1), interacting only with its nearest neighbors, as illustrated in Figure 3.1. Figure 3.1: A 4-spin Ising model with periodic boundary conditions. Each spin can point up (+1) or down (−1) and interacts with its two neighboring spins. The energy of this system is given by: \\[ H(\\sigma) = -\\sum_{\\langle i,j \\rangle} J_{ij} \\sigma_i \\sigma_j \\] Where the sum runs over adjacent pairs of spins, with \\(J\\) representing the interaction strength. For ferromagnetic coupling (\\(J &gt; 0\\)), parallel spins have lower energy than antiparallel ones. With just four spins, we have only \\(2^4 = 16\\) possible configurations. These configurations fall into three energy levels, as shown in Figure 3.2: Highest energy (\\(+4J\\)): Alternating up and down spins (antiferromagnetic). Two configurations with \\(|m| = 0\\). Intermediate energy (\\(0J\\)): Twelve configurations with mixed spin alignments. Ground state (\\(−4J\\)): All spins aligned (either all up or all down — ferromagnetic). Two configurations with magnitude of magnetisation \\(|m| = 4\\). Figure 3.2: All 16 possible spin configurations for a 4-spin Ising model, showing energy values and magnetisation values. A Metropolis Monte Carlo simulation of this system works as follows: Start with a random arrangement of the four spins. At each step, randomly select one spin and propose flipping it. Calculate the energy change \\(\\Delta E\\) that would result from this flip. Apply the Metropolis criterion: accept the flip if \\(\\Delta E \\leq 0\\); otherwise accept with probability \\(\\exp(-\\Delta E/kT)\\). Record the new configuration (or repeat the current one if the move was rejected). Figure 3.3 illustrates a portion of a Monte Carlo trajectory, showing how the system evolves through a sequence of configurations by accepting or rejecting proposed spin flips. Notice how the simulation only occasionally accepts moves that would increase the energy. Figure 3.3: A portion of a Monte Carlo trajectory showing how the system evolves through a sequence of configurations. Each row shows the current spin state, the proposed move (highlighting the spin flipped in this move), the energy change for the proposed move, and the probability of the move being accepted. For proposed moves that would increase the total energy, i.e., \\(P_\\mathrm{acc} &lt; 1\\), the table also shows the random number generated. Finally the table records whether the proposed move was accepted or rejected. After an initial equilibration period, the Metropolis algorithm ensures that the frequency with which we sample each state matches its Boltzmann probability. This means we can calculate thermodynamic properties by simply averaging over our collected samples. For instance, calculating the average magnetisation magnitude \\(\\langle |M| \\rangle\\) is straightforward—we average the magnetisation magnitudes from our sampled configurations: \\[ \\langle |M| \\rangle \\approx \\frac{1}{N} \\sum_{i=1}^N |M|_i \\] At very low temperatures, the system remains “frozen” in one of the ground states with all spins aligned, giving \\(\\langle |M| \\rangle = 4\\). As temperature increases, thermal fluctuations allow higher-energy configurations to be sampled, and the average magnetisation decreases, eventually approaching the high-temperature limit of \\(\\langle |M| \\rangle = 1.5\\) where all configurations become equally probable. Figure 3.4: Average magnetisation magnitude, \\(\\langle |M| \\rangle\\), as a function of temperature, for a 4-spin Ising system with \\(J=0.012\\) eV, calculated using Metropolis Monte Carlo (circles) and by direct summation of the exact result (solid line). The horizontal dashed line shows the high-temperature limit result, \\(\\langle |M| \\rangle=1.5\\). A key strength of the Monte Carlo method is that the procedure remains the same regardless of system size. For this \\(4\\)-spin system, we have only \\(16\\) total states, and we can evaluate \\(\\langle |M| \\rangle\\) by direct enumeration. However, for larger systems, direct enumeration quickly becomes impossible: a \\(100\\)-spin system has \\(2^{100} \\approx 1.27 \\times 10^{30}\\) states! Yet the Monte Carlo procedure remains exactly the same—we still select and flip individual spins, evaluate energy changes, and apply the Metropolis criterion. Through this local sampling process, the method efficiently explores the states with significant Boltzmann weights without requiring exhaustive enumeration. 3.7 Example: Butane Conformations Moving from discrete to continuous configuration space, let’s examine a more chemical example: sampling the conformational preferences of butane (C₄H₁₀). This simple hydrocarbon serves as an excellent model system for studying torsional preferences in molecules. The energy of butane varies with rotation around its central carbon-carbon bond, characterized by the dihedral angle \\(\\phi\\). This torsional energy landscape features three main conformations: The anti conformation (\\(\\phi = 180°\\)): This extended structure minimizes steric interactions between terminal methyl groups, making it the global energy minimum. Two equivalent gauche conformations (\\(\\phi \\approx 60°\\) and \\(\\phi \\approx 300°\\)): These conformations introduce some steric strain but remain thermally accessible at room temperature. The eclipsed or cis conformation (\\(\\phi = 0°\\)): This high-energy conformation places the methyl groups in close proximity, creating steric repulsion. The potential energy as a function of this dihedral angle can be approximated by: \\[\\begin{equation} U(\\phi) = A_0 + A_1(1+\\cos\\phi) + A_2(1-\\cos2\\phi) + A_3(1+\\cos3\\phi) \\tag{3.1} \\end{equation}\\] Where the coefficients \\(A_i\\) determine the relative energies of the different conformations. This functional form captures the threefold periodicity and energy barriers of butane’s rotational potential. This potential energy function creates distinct wells corresponding to the anti and gauche conformations, separated by energy barriers. These barriers represent configurations where methyl groups come into close proximity, creating unfavorable steric interactions. Figure 3.5: Potential energy surface for butane’s dihedral angle rotation, modelled using Equation (3.1). Note the global minimum at 180° (anti conformation) and the two local minima at approximately 60° and 300° (gauche conformations), separated by energy barriers representing steric clash configurations. A Metropolis Monte Carlo simulation of butane’s conformational space proceeds as follows: Begin with an initial dihedral angle, perhaps \\(\\phi = 180°\\) (the anti conformation). Propose a new dihedral angle by adding a small random perturbation: \\(\\phi&#39; = \\phi + \\Delta\\phi\\), where \\(\\Delta\\phi\\) is chosen from a symmetric distribution. The size of \\(\\Delta\\phi\\) affects sampling efficiency—too small and the simulation explores conformational space slowly; too large and most moves are rejected due to the resulting high-energy configurations. Calculate the energy change: \\(\\Delta U = U(\\phi&#39;) - U(\\phi)\\). Apply the Metropolis criterion to decide whether to accept the new angle: If \\(\\Delta U \\leq 0\\), accept the move. If \\(\\Delta U &gt; 0\\), accept with probability \\(\\exp(-\\Delta U/kT)\\). Record the current dihedral angle (either the new one if accepted, or the previous one if rejected). Repeat steps 2-5 many times to generate a distribution of dihedral angles. After sufficient sampling, the histogram of dihedral angles visited during the simulation reveals the conformational preferences of butane at the simulation temperature. Figure 3.6 shows results from a simulation at 500 K. Figure 3.6: Probability distribution of butane’s dihedral angles at 500 K from Metropolis Monte Carlo sampling (histogram). The solid red line shows the exact Boltzmann distribution calculated analytically. Note the excellent agreement between simulation and theory, with the anti conformation (180°) being most populated, followed by the two gauche conformations at approximately 60° and 300°. The agreement between the Monte Carlo histogram and the exact distribution (red line) confirms that our sampling correctly reproduces the Boltzmann distribution. The anti conformation (180°) is most populated, with the gauche conformations (around 60° and 300°) also showing significant occupancy. 3.8 Equilibration and Sampling When beginning a Monte Carlo simulation, the initial configuration is often far from representative of typical equilibrium structures. To avoid biasing results, data from an initial “equilibration” or “burn-in” phase must be discarded before collecting statistics for analysis. From a theoretical perspective, equilibration is precisely defined as the time required for the Markov chain to converge to its stationary distribution—in our case, the Boltzmann distribution. At this point, the simulation has effectively “forgotten” its initial configuration and is sampling all relevant regions of configuration space with their correct Boltzmann probabilities. In practice, determining when equilibration has occurred requires systematic assessment through several quantitative approaches: Energy monitoring: Tracking the system’s energy throughout the simulation. Initially, energy often exhibits a systematic drift that transitions to stochastic fluctuations around a stable mean once local equilibration is achieved. Property stabilization: Monitoring key observable properties until their running averages and distributions stabilize within statistical uncertainty. Multiple starting points: Initiating several simulations from different configurations. Convergence to statistically equivalent results suggests proper equilibration in each case. Autocorrelation analysis: Calculating time correlation functions for relevant properties to quantify the decorrelation time of the simulation. It is important to recognize that these practical indicators of equilibration may indicate only local rather than global equilibration. A simulation can exhibit all the hallmarks of proper equilibration—stable energy fluctuations, consistent property averages, and decaying correlations—while remaining confined to a restricted region of configuration space. In such cases, the system reaches a metastable equilibrium within a subset of the full configurational ensemble, rather than the true global equilibrium defined by the complete Boltzmann distribution. This limitation represents one of the fundamental challenges in Monte Carlo simulations of complex systems. When multiple regions of configuration space are separated by high energy barriers, transitions between these regions become exceedingly rare at relevant temperatures. Consequently, a simulation may appear fully equilibrated within a single region while never sampling other important configurations. Depending on the system complexity and the height of energy barriers, adequate sampling may necessitate significantly extended equilibration periods—sometimes requiring thousands or even millions of Monte Carlo steps. 3.9 Temperature Effects and Sampling Challenges Temperature determines the equilibrium distribution we sample in Monte Carlo simulations through its direct presence in the Metropolis acceptance criterion: \\[ \\text{acc}(i \\to j) = \\min(1, \\exp(-(U_j-U_i)/kT)) \\] This temperature dependence affects our simulations in two distinct ways. First, it defines the theoretical Boltzmann distribution we aim to sample—at different temperatures, the same configurations have different equilibrium probabilities. Second, it influences the practical efficiency with which our simulation explores configuration space. Figure 3.7: Probability distributions of butane’s dihedral angles at increasing temperatures (500 K, 1000 K, and 2000 K). Elevated temperatures progressively flatten the distribution, with barriers becoming less significant as temperature increases. At 2000 K, the distribution approaches uniformity, indicating that thermal energy has largely overcome the rotational barriers. Figure 3.7 demonstrates how increasing temperature transforms the distribution of butane dihedral angles. As temperature rises from 500 K to 1000 K and further to 2000 K, we observe a progressive flattening of the probability landscape. This flattening occurs because temperature effectively rescales the potential energy surface—dividing all energy differences by \\(kT\\) in the Boltzmann factor. At 1000 K, the distribution shows notable changes compared to 500 K. The central anti conformation at 180° remains distinguishable but with reduced dominance, while the gauche conformations at approximately 60° and 300° gain population. At 2000 K, the distribution approaches uniformity. The three major conformations have similar probabilities, with only subtle differences remaining between energy minima and barriers. At this high temperature, the exponential term in the Metropolis criterion approaches unity even for substantial energy increases, causing the system to accept most proposed moves regardless of their energetic consequences. 3.9.1 Sampling Problems at Low Temperature Figure 3.8: Probability distribution of butane’s dihedral angles from a simulation at 50 K (histogram) compared with the theoretical Boltzmann distribution (red line). The simulation, initialized at φ = 60°, fails to sample the global minimum at 180° adequately and completely misses the third minimum near 270°, illustrating how low temperatures can trap simulations in local regions of configuration space. While the simulations at 500 K and above successfully sample the full range of dihedral angles and accurately reproduce the theoretical Boltzmann distribution, Figure 3.8 reveals a fundamental sampling problem at low temperature. This simulation at 50 K was initialized with \\(\\phi\\) = 60°, and it remains trapped in the local minimum near this angle for much of the simulation time. Eventually, it transitions to the global minimum at 180°, but the relative populations between these two minima remain incorrect. The third minimum at approximately 270° is never visited during the simulation, though at this temperature even the exact distribution shows this conformation has very low probability. This butane example at 50 K illustrates a general issue that affects Monte Carlo simulations of many chemical systems. When the available thermal energy (\\(kT\\)) is small relative to the energy barriers separating different configurations, the Metropolis acceptance probability for barrier-crossing moves becomes vanishingly small. Consequently, the simulation may remain trapped in a subset of the full configuration space for the entire simulation duration. 3.10 The Ergodic Hypothesis The butane example at 50 K points to a fundamental assumption underlying Monte Carlo simulations: the ergodic hypothesis. This hypothesis states that the time average of a property (calculated from a single system observed for a sufficiently long time) equals the ensemble average (calculated across many systems at one moment, each sampled according to the appropriate equilibrium distribution). When we run a single Metropolis Monte Carlo trajectory and calculate averages from it, we are implicitly assuming that our simulation has adequately sampled the entire relevant configuration space according to the Boltzmann distribution. Only if this assumption holds can we expect our calculated properties to match the true equilibrium thermodynamic values. For a Markov chain Monte Carlo simulation to be ergodic, it must satisfy two mathematical conditions: Irreducibility: The Markov chain must be able to reach any state from any other state through a sequence of allowed moves. Aperiodicity: The chain must not cycle deterministically through a fixed sequence of states. As the 50 K butane simulation demonstrates, this assumption can fail in practical applications. Despite the Metropolis algorithm’s mathematical guarantee of eventually sampling the correct Boltzmann distribution, the timescale required to adequately sample all relevant configurations might exceed any feasible simulation length. The 50 K simulation remains trapped in a subset of the configuration space, producing results that reflect only part of the full Boltzmann-weighted ensemble. In this case, the time average from our simulation does not equal the true ensemble average—the ergodic hypothesis breaks down. While the Metropolis algorithm theoretically allows transitions between all possible states, in practice high energy barriers can create situations where certain regions of configuration space become effectively isolated from others. This is analogous to our UK height sampling example from Lecture 2—if our random walker begins in Edinburgh without efficient transportation, they might thoroughly explore the Scottish cities but never reach London or Cardiff during the course of our survey. The heights measured would accurately represent Scotland’s population, but fail to capture the demographics of the entire UK. Similarly, when energy barriers partition configuration space, the simulation results depend heavily on the initial configuration and fail to represent the complete equilibrium distribution. This practical limitation represents one of the most significant challenges in applying Monte Carlo methods to complex chemical systems. 3.11 Summary In this lecture, we’ve developed the mathematical foundation for Metropolis Monte Carlo and explored its practical implementation through examples and key considerations. The principle of detailed balance provides the necessary conditions for a Markov chain to sample from the Boltzmann distribution, while the Metropolis acceptance criterion offers an elegant solution to satisfy these conditions. The key concepts we’ve explored include: The mathematical foundation of detailed balance and its application to chemical systems How the Metropolis criterion solves the sampling problem for the Boltzmann distribution Why counting rejected states is crucial for correct statistical weighting The application of Metropolis Monte Carlo to both discrete (Ising) and continuous (butane) systems Equilibration protocols and their limitations in complex systems The ergodic hypothesis as both the theoretical foundation and practical challenge How temperature fundamentally alters sampling behavior The power of the Metropolis Monte Carlo method lies in its practicality. It requires only local energy calculations rather than global partition functions, works with any energy function, and can be implemented in remarkably few lines of code. With a simple acceptance rule, we can sample from the Boltzmann distribution for systems ranging from simple spin models to complex molecules, focusing our computational resources on the physically relevant regions of configuration space. Direct sampling from the Boltzmann distribution also provides maximum statistical efficiency—we get the lowest possible variance in our estimates for a fixed number of samples.↩︎ "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
