[["index.html", "CH22013 Lecture Notes About", " CH22013 Lecture Notes Benjamin J. Morgan 2025-03-21 About These notes accompany the 2025 CH22013 lecture course on Monte Carlo methods. "],["monte-carlo-methods-in-computational-chemistry.html", "Lecture 1 Monte Carlo Methods in Computational Chemistry 1.1 Lecture 1: Introduction to Monte Carlo Methods", " Lecture 1 Monte Carlo Methods in Computational Chemistry 1.1 Lecture 1: Introduction to Monte Carlo Methods 1.1.1 Introduction to Averaging &amp; Sampling Chemistry is fundamentally a statistical science. Macroscopic properties such as pressure, temperature, and heat capacity emerge from the collective behavior of approximately \\(10^{23}\\) atoms or molecules. These observable quantities represent averages over an immense number of microscopic states. A central challenge in computational chemistry is how to accurately estimate these macroscopic properties without having to evaluate every possible molecular arrangement. 1.1.1.1 The Statistical Nature of Chemical Systems When we measure properties of chemical systems in the laboratory, we observe the average behavior of countless molecules over the duration of our measurement. Even the simplest systems—gases, liquids, or solids—involve enormous numbers of possible arrangements of atoms, with molecules constantly moving, rotating, and vibrating at finite temperatures. To accurately predict these macroscopic measurements, we need to account for this diversity of molecular configurations. Ideally, we would calculate our property of interest for every possible configuration, weight each result by the probability of that configuration occurring, and then sum these weighted values. The mathematical expression for this average is: \\[\\langle A \\rangle = \\sum A(\\mathbf{r}) \\times P(\\mathbf{r})\\] Where \\(\\mathbf{r}\\) represents a particular configuration of the system, and \\(P(\\mathbf{r})\\) is the probability of finding the system in that configuration. 1.1.1.2 Probability Distributions \\(P(\\mathbf{r})\\) represents a probability distribution, which describes the likelihood of finding the system in each possible configuration. Probability distributions form the mathematical foundation for describing systems with inherent variability. Probability distributions come in two forms: Discrete distributions apply when a variable can only take specific, countable values. For these, we use a probability mass function (PMF) that gives the probability of each possible outcome. For example, when rolling a fair six-sided die, each number (1-6) has a probability of 1/6. Another example is counting heads in four coin flips, which follows a binomial distribution where the probability of k heads is \\(\\binom{4}{k} \\times (1/2)^4\\). Continuous distributions apply when a variable can take any value within a continuous range. These use a probability density function (PDF) where the probability of finding the variable in a specific range equals the area under the PDF curve over that range. A simple example is a random point selected along a line segment from 0 to 1, which follows a uniform continuous distribution with constant probability density. In all probability distributions, the total probability must equal 1, meaning the system must exist in some state. The average (expected value) of any property A is calculated by weighting each possible value by its probability and summing over all possibilities—exactly the formula we saw earlier for chemical systems. 1.1.1.3 The Boltzmann Distribution In chemical systems, the probability distribution that governs molecular configurations is the Boltzmann distribution: \\[P(\\mathbf{r}) \\propto \\exp(-U(\\mathbf{r})/kT)\\] Here, \\(U(\\mathbf{r})\\) is the potential energy of configuration \\(\\mathbf{r}\\), \\(k\\) is Boltzmann’s constant, and \\(T\\) is the temperature. This relationship reveals a fundamental principle in physical chemistry: lower-energy configurations are exponentially more probable than higher-energy ones. At room temperature (298 K), a configuration that is just 6 kJ/mol higher in energy is approximately 10 times less probable than the minimum energy state. Temperature determines how strongly the system favors low-energy states—at high temperatures, the distribution becomes more uniform, while at low temperatures, the system is increasingly restricted to the lowest energy states. To create a valid probability distribution, the probabilities must sum to 1: \\[\\sum_i P(\\mathbf{r}) = 1\\] We achieve this by including a normalization constant, \\(Z\\): \\[P(\\mathbf{r}) = \\frac{\\exp(-U(\\mathbf{r})/kT)}{Z}\\] This constant \\(Z\\) is called the “partition function,” defined as: \\[Z = \\sum \\exp(-U(\\mathbf{r})/kT)\\] The partition function plays a central role in statistical mechanics and thermodynamics, connecting microscopic configurations to macroscopic properties. 1.1.1.4 The Computational Challenge Let’s revisit our fundamental problem. To calculate the thermodynamic average of a property A, we need to evaluate: \\[\\langle A \\rangle = \\sum A(\\mathbf{r}) \\times P(\\mathbf{r})\\] Where \\(P(\\mathbf{r})\\) is the Boltzmann distribution: \\[P(\\mathbf{r}) = \\frac{\\exp(-U(\\mathbf{r})/kT)}{Z}\\] A direct approach to this calculation would require: 1. Generating all possible configurations of our system 2. Computing the property A and energy for each configuration 3. Calculating the weighted sum The obstacle lies in the sheer number of possible configurations for any realistic chemical system. Consider a simple example: a 10×10 array of surface sites where we want to model the adsorption of 50 molecules. This system has approximately \\(10^{29}\\) possible configurations—more than the number of stars in the observable universe. Direct enumeration becomes impossible. For most chemical systems, the situation is even more extreme. A small protein in solution might have millions of relevant conformations. A metal catalyst with multiple reaction pathways or a polymer chain sampling different spatial arrangements presents an effectively infinite configuration space. This combinatorial explosion makes direct evaluation computationally intractable—even the most powerful supercomputers cannot handle such calculations. 1.1.2 The Solution: Statistical Sampling Rather than calculating the exact sum, which we’ve established is computationally intractable, we can estimate it through sampling—selecting a subset of configurations that represent the full distribution, evaluating our property of interest for these samples, and calculating their average. This concept of sampling is fundamental throughout science and statistics. Consider estimating the average height of people in Britain. Measuring everyone’s height is impractical, but we can measure a representative sample and use that sample’s average as an estimate of the true population average. The key requirement is that our sample must be representative—it should reflect the true probability distribution of the property we’re measuring. For instance, sampling players arriving for a basketball tournament would likely produce a significant overestimate of the average British height, as basketball players tend to be taller than the general population. In contrast, measuring the heights of people passing by on a street corner on a Saturday afternoon would provide a more representative sample of the British population. For chemical systems, this means generating configurations according to the Boltzmann distribution, calculating our property of interest for each configuration, and then averaging these values: \\[\\langle A \\rangle \\approx \\frac{1}{N} \\sum_{i=1}^{N} A(\\mathbf{r}_i)\\] Where the configurations \\(\\mathbf{r}_i\\) are selected with probability proportional to \\(\\exp(-U(\\mathbf{r}_i)/kT)\\). Note that when we sample configurations with the correct Boltzmann weighting, we do not need to apply additional weighting factors in our averaging formula. This simplification occurs because the probability distribution is already incorporated into our sampling process. This principle applies to any sampling problem—if we sample observations directly from the true probability distribution of the population, we can use simple averaging; otherwise, we must apply appropriate weighting factors to correct for sampling bias. 1.1.2.1 Statistical Uncertainty and Sample Size An important aspect of sampling is that we always obtain estimates that carry statistical uncertainty. If we were to sample heights of passers-by on consecutive weekends, we would almost certainly observe different individuals and calculate different estimates of the mean British height. This variability is intrinsic to sampling methods. 1.1.3 Two Approaches to Sampling Two principal methods have been developed to address the sampling challenge in computational chemistry: 1.1.3.1 Molecular Dynamics Approach Molecular Dynamics (MD) simulates atomic motion according to Newton’s laws. By following these physical trajectories, MD can sample configurations according to their Boltzmann probabilities. When a simulation trajectory visits a suitably representative set of configurations in the relevant regions of configuration space, the time average provides a good approximation of the desired ensemble average: \\[\\langle A \\rangle \\approx \\frac{1}{M} \\sum_{i=1}^{M} A(\\mathbf{r}_i)\\] Where \\(M\\) is the number of time steps. However, the effectiveness of MD sampling depends on the system’s energy landscape. Consider a protein folding example: if high energy barriers separate different conformational states, the protein may remain trapped in one conformation for the entire simulation duration. The resulting time average would reflect only a small subset of the relevant configuration space, not the true equilibrium ensemble. Timescales present another challenge. Many important chemical processes occur on microsecond to second timescales, while individual MD time steps typically represent femtoseconds. This creates a fundamental gap between simulation capability and the time needed to observe certain phenomena. For instance, studying a slow conformational change or a rare reaction event may require prohibitively long simulation times. Additionally, some systems inherently resist treatment via continuous dynamics. Lattice models with discrete site occupancies, magnetic materials with fixed spin orientations, or any problem where variables can only take discrete values often require different sampling approaches altogether. 1.1.3.2 Monte Carlo Approach Monte Carlo (MC) methods, named after the famous casino district in Monaco, use random numbers to estimate complex averages through sampling. This approach offers a powerful alternative to Molecular Dynamics for calculating equilibrium properties. In its simplest form, Monte Carlo sampling involves generating configurations using random numbers, evaluating the property of interest for each configuration, and computing the average of these values. 1.1.4 Fundamental Monte Carlo Examples Before addressing the sampling challenges in chemical systems, let’s examine two classic examples that illustrate the power of Monte Carlo methods with uniform sampling. These examples demonstrate the core principles using simple problems where each possible outcome has an equal probability of occurring. 1.1.4.1 Estimating π by Monte Carlo Integration One of the simplest demonstrations of Monte Carlo methods is estimating the value of π. Consider a circle with radius 1 inscribed inside a square with side length 2. The area of the circle is π, while the area of the square is 4. Therefore, the ratio of these areas is π/4. We can estimate this ratio by randomly placing points within the square and counting what fraction fall inside the circle. The procedure involves generating N random points with coordinates (x,y), where x and y are uniformly distributed between -1 and 1. We then count how many points M satisfy \\(x^2 + y^2 \\leq 1\\), which indicates they fall within the circle. The estimate for π is given by: \\(\\pi \\approx 4 \\times M/N\\). This approach demonstrates how random sampling can solve a deterministic problem. 1.1.4.2 Function Averaging and Numerical Integration Our second example involves calculating the average value of a function over a specific interval. Consider finding the average value of \\(\\sin^2(x)\\) over the interval [0,π]. Mathematically, this average is defined as: \\[\\text{Average value} = \\frac{1}{\\pi} \\times \\int_0^{\\pi} \\sin^2(x) dx\\] The analytical solution to this integral is 1/2. Using Monte Carlo methods, we can estimate this average by generating uniform random x-values between 0 and π, calculating \\(\\sin^2(x)\\) for each point, and then averaging these results. This procedure can be generalized to estimate any definite integral: \\[\\int_a^b f(x) dx \\approx (b-a) \\times \\frac{1}{N} \\sum_{i=1}^{N} f(x_i)\\] Where \\(x_1, x_2, ..., x_N\\) are uniform random numbers between a and b. The strength of this approach becomes apparent when dealing with multi-dimensional integrals, where traditional numerical methods become exponentially more expensive as dimensionality increases. 1.1.5 Statistical Uncertainty in Monte Carlo Methods A fundamental characteristic of all Monte Carlo methods is that they produce estimates rather than exact answers. Each time we run a Monte Carlo simulation with a different sequence of random numbers, we get a slightly different result. This variation is the source of statistical uncertainty in Monte Carlo methods. Unlike deterministic methods, which might have errors from approximations but give the same answer every time, Monte Carlo methods produce different answers on different runs. This inherent variability means we must consider Monte Carlo results as estimates with associated uncertainty. The precision of these estimates improves as we increase the number of samples. Statistical uncertainty decreases proportionally to \\(1/\\sqrt{N}\\), where N is the number of random samples. To reduce the uncertainty by half, we need to use four times as many samples. This scaling behavior is characteristic of random sampling methods and remains independent of the dimensionality of the problem—a significant advantage in high-dimensional applications. When reporting results from Monte Carlo simulations, it is essential to always include the associated uncertainties alongside the estimated values. This practice is a fundamental aspect of scientific reporting in computational chemistry and allows others to properly evaluate the reliability of the results. 1.1.6 Summary and Preview 1.1.6.1 Key Takeaways from Lecture 1 Monte Carlo methods provide powerful tools for estimating averages in complex systems through statistical sampling. We’ve explored: The basic principles of random sampling How Monte Carlo techniques can be applied to mathematical problems The inherent statistical uncertainty in Monte Carlo results and how it decreases with sample size The examples in this lecture have all used uniform sampling—where each possible outcome has an equal probability of being selected. This approach works well for many mathematical problems, including certain numerical integration tasks and geometrical probability calculations. 1.1.6.2 Looking Ahead to Lecture 2 In the next lecture, we’ll extend Monte Carlo methods to chemical systems, which present additional challenges. We’ll explore how to sample molecular configurations according to the Boltzmann distribution introduced earlier, allowing us to calculate thermodynamic properties of realistic chemical systems. The Metropolis algorithm will provide a solution to the challenge of sampling from the Boltzmann distribution without knowing the partition function. This method has become a cornerstone in computational chemistry, enabling Monte Carlo simulations across a wide range of applications. "],["mc-chemical.html", "Lecture 2 Monte Carlo Methods in Computational Chemistry 2.1 Lecture 2: Monte Carlo Methods Applied to Chemical Systems", " Lecture 2 Monte Carlo Methods in Computational Chemistry 2.1 Lecture 2: Monte Carlo Methods Applied to Chemical Systems 2.1.1 From Uniform to Non-Uniform Sampling In our previous lecture, we explored Monte Carlo methods using uniform sampling. We saw how randomly selecting points with equal probability allows us to estimate mathematical quantities like \\(\\pi\\) or evaluate definite integrals. These examples worked well because each possible sample point had the same likelihood of occurring. Chemical systems, however, present a different challenge. In molecular systems, configurations are not equally probable but are distributed according to their energies. The probability of observing a particular molecular configuration depends on its energy according to the Boltzmann distribution: \\(P(\\mathbf{r}) \\propto \\exp(-U(\\mathbf{r})/kT)\\) As discussed in Lecture 1, this distribution means low-energy configurations are exponentially more probable than high-energy ones. This fundamental property governs the behavior of all molecular systems at equilibrium. This non-uniform probability distribution changes how we must calculate averages. With uniform sampling, as we saw in Lecture 1, we could simply average our results: \\[\\langle A \\rangle \\approx \\frac{1}{N} \\sum_{i=1}^N A(\\mathbf{r}_i)\\] For chemical systems with their non-uniform probabilities, we need a weighted average: \\[\\langle A \\rangle \\approx \\frac{\\sum_{i=1}^N A(\\mathbf{r}_i) \\times w(\\mathbf{r}_i)}{\\sum_{i=1}^N w(\\mathbf{r}_i)}\\] The weight \\(w(\\mathbf{r}_i)\\) represents the relative probability of configuration \\(\\mathbf{r}_i\\), which follows the Boltzmann distribution: \\(w(\\mathbf{r}_i) \\propto \\exp(-U(\\mathbf{r}_i)/kT)\\). This presents us with a new challenge: how do we generate samples that follow the Boltzmann distribution? This is the central question we’ll address in this lecture. 2.1.2 The Partition Function Challenge In Lecture 1, we introduced the partition function \\(Z\\) as the normalization constant in the Boltzmann distribution: \\(P(\\mathbf{r}) = \\frac{\\exp(-U(\\mathbf{r})/kT)}{Z}\\) Where: \\(Z = \\sum \\exp(-U(\\mathbf{r})/kT)\\) This normalization ensures that probabilities sum to 1 and provides connections to thermodynamic properties. However, calculating the partition function directly creates a fundamental computational challenge. To determine \\(Z\\) exactly, we would need to sum over all possible configurations of our system—the very sum we’re trying to avoid by using sampling methods. For most chemical systems, the number of possible configurations is astronomical. Even a small protein might have more possible conformations than there are atoms in the universe. This creates a practical dilemma: to calculate the Boltzmann probabilities correctly, we need to know \\(Z\\), but calculating \\(Z\\) requires evaluating all possible states. We need a method that can sample according to the Boltzmann distribution without knowing \\(Z\\) in advance. 2.1.3 The Challenge of High Dimensions Our sampling challenge is further complicated by what mathematicians call the “curse of dimensionality.” This refers to how the volume of configuration space grows exponentially with its dimension. A simple example illustrates this problem mathematically. Consider the volume ratio of a hypersphere inscribed within a hypercube: In 2D: A circle within a square occupies about 79% of the square’s area In 3D: A sphere within a cube occupies only about 52% of the cube’s volume In 10D: The hypersphere occupies a mere 0.25% of the hypercube In 100D: The ratio becomes extremely small (approximately \\(10^{-70}\\)) For molecular systems, the dimensionality equals the degrees of freedom. Each atom has three spatial coordinates, so a system with \\(N\\) atoms has \\(3N\\) dimensions (minus six for overall translation and rotation of the entire molecule). Even a small protein with 100 residues easily has thousands of dimensions. This high dimensionality creates a severe sampling problem. If we were to use uniform sampling in such a high-dimensional space, the vast majority of randomly generated configurations would have extremely low Boltzmann probability—typically corresponding to physically impossible structures with severe atomic overlaps. The curse of dimensionality means that as system size increases, the fraction of configuration space with significant Boltzmann weight becomes vanishingly small, making uniform sampling hopelessly inefficient. 2.1.4 The Solution: Markov Chain Monte Carlo We’ve identified two interconnected challenges: we can’t calculate the Boltzmann distribution directly without knowing the partition function, and even if we could, uniform sampling becomes hopelessly inefficient in high dimensions. Fortunately, a class of methods known as Markov Chain Monte Carlo (MCMC) provides an elegant solution to both problems. Let’s return to our example from Lecture 1 of estimating the average height of people in Britain. Imagine if instead of sampling individuals directly, we decided to use a geographical approach: randomly selecting 100m × 100m squares on a map of Britain, and measuring everyone within each selected square. This approach would be extremely inefficient. Many squares would contain no people at all (in rural areas, forests, lakes), while a few squares in London or Manchester might contain hundreds of people. To get a representative sample, we would need to select an enormous number of squares. A more efficient approach would be to preferentially sample areas with higher population density. Moreover, we could use the fact that population density tends to be spatially correlated—if one square has many people, neighboring squares likely do as well. This is the key insight of MCMC. Instead of generating independent random samples (squares) with uniform probability, we create a “chain” of samples where each new sample is generated based on the current one. In our population example, we might start in a random square, then preferentially move to neighboring squares with higher population. Over time, we would naturally spend most of our sampling effort in densely populated areas, with occasional visits to less populated regions. For molecular systems, MCMC creates a random walk through configuration space that naturally spends more time in high-probability (low-energy) regions, in proportion to their Boltzmann weight. This solves both our challenges: we sample efficiently from regions that matter most, and we never need to calculate the partition function explicitly. 2.1.5 What is a Markov Chain? Before diving into the full algorithm, let’s understand what makes something a “Markov chain.” A Markov chain is a sequence of states where the probability of the next state depends only on the current state, not on the sequence of states that preceded it. This “memoryless” property is known as the Markov property. A simple example is a random walk where the next position depends only on the current position and some transition rules. The future evolution of the system depends only on its present state, not on how it arrived at that state. Markov chains are characterized by transition probabilities—the likelihood of moving from one state to another. For a system with discrete states, these probabilities form a transition matrix. After many steps, many Markov chains converge to a “stationary distribution” where the probability of finding the system in each state no longer changes over time. This stationary distribution is the key to our solution. If we design our Markov chain so that its stationary distribution matches the Boltzmann distribution, then by running the chain for a sufficient number of steps, we’ll naturally sample configurations with the correct probabilities—all without ever having to calculate the partition function. 2.1.6 The Principle of Detailed Balance How do we design a Markov chain that converges to the Boltzmann distribution? The answer lies in a principle called “detailed balance.” At equilibrium, the overall population of each state in a Markov chain remains constant. This means that the total probability flow into a state must equal the total flow out of that state. This is called “global balance.” Detailed balance is a stronger condition that ensures global balance. It states that for each pair of states, the flow from state i to state j must exactly equal the flow from j back to i: \\(\\pi(i) \\times P(i \\to j) = \\pi(j) \\times P(j \\to i)\\) Here, \\(\\pi(i)\\) is the equilibrium probability of state i, and \\(P(i \\to j)\\) is the transition probability from state i to state j. For chemical systems, we want \\(\\pi(i)\\) to match the Boltzmann distribution. Substituting this in: \\(\\exp(-U(i)/kT) \\times P(i \\to j) = \\exp(-U(j)/kT) \\times P(j \\to i)\\) Rearranging: \\(\\frac{P(i \\to j)}{P(j \\to i)} = \\frac{\\exp(-U(j)/kT)}{\\exp(-U(i)/kT)} = \\exp(-(U(j)-U(i))/kT)\\) This equation gives us a constraint on the transition probabilities. Any Markov chain that satisfies this relationship will have the Boltzmann distribution as its stationary distribution. The challenge is now to design practical transitions that satisfy this constraint. 2.1.7 The Metropolis Algorithm In 1953, Nicholas Metropolis and colleagues published an algorithm that provides a simple and powerful way to satisfy detailed balance. Their approach has become a cornerstone of computational chemistry and physics. The key insight of the Metropolis method is to design an acceptance criterion that ensures sampling from the Boltzmann distribution while satisfying detailed balance. The algorithm separates the transition probability into two parts: \\(P(i \\to j) = \\alpha(i \\to j) \\times \\text{acc}(i \\to j)\\) Where \\(\\alpha(i \\to j)\\) is the proposal probability and \\(\\text{acc}(i \\to j)\\) is the acceptance probability. The simplest approach is to use symmetric proposal probabilities where \\(\\alpha(i \\to j) = \\alpha(j \\to i)\\). This might involve, for example, randomly displacing an atom in any direction with equal probability. With this simplification, our detailed balance condition becomes: \\(\\frac{\\text{acc}(i \\to j)}{\\text{acc}(j \\to i)} = \\exp(-(U(j)-U(i))/kT)\\) The Metropolis solution to this equation is: \\(\\text{acc}(i \\to j) = \\min(1, \\exp(-(U(j)-U(i))/kT))\\) This elegant formula leads to a simple rule: If the proposed move decreases the energy (\\(U(j) &lt; U(i)\\)), accept it with probability 1 (always) If the proposed move increases the energy, accept it with probability \\(\\exp(-(U(j)-U(i))/kT)\\) This acceptance rule makes intuitive sense. The system always accepts moves to lower energy states, just as a ball naturally rolls downhill. But it sometimes accepts moves to higher energy states, with a probability that decreases exponentially with the energy increase. This allows the system to escape local energy minima and explore the full configuration space. 2.1.8 The Metropolis Monte Carlo Algorithm Let’s put everything together into a practical algorithm for simulating chemical systems: Start with an initial configuration of your system. Calculate the energy of this initial configuration \\(U(\\mathbf{r})\\). Propose a move to a new configuration \\(\\mathbf{r}&#39;\\). This might involve randomly displacing an atom, rotating a dihedral angle, or some other change to the system. Calculate the energy of the new configuration \\(U(\\mathbf{r}&#39;)\\). Compute the energy difference: \\(\\Delta U = U(\\mathbf{r}&#39;) - U(\\mathbf{r})\\). Apply the Metropolis criterion to decide whether to accept the move: If \\(\\Delta U \\leq 0\\), accept the move. If \\(\\Delta U &gt; 0\\), generate a random number \\(\\xi\\) between 0 and 1. If \\(\\xi &lt; \\exp(-\\Delta U/kT)\\), accept the move. Otherwise, reject the move. If the move is accepted, update your current configuration to \\(\\mathbf{r}&#39;\\). If rejected, retain the original configuration \\(\\mathbf{r}\\). Calculate any properties of interest for the current configuration. Return to step 3 and repeat for many iterations. Compute the average of your calculated properties over all sampled configurations. This algorithm naturally generates configurations according to the Boltzmann distribution. The beauty of the approach is that we never need to calculate the partition function—the acceptance rule ensures the correct distribution without requiring normalization. 2.1.9 The Role of Temperature in Monte Carlo Sampling Temperature plays a crucial role in Monte Carlo simulations, affecting both the equilibrium distribution and sampling efficiency. Looking at the Metropolis acceptance criterion: \\(\\text{acc}(i \\to j) = \\min(1, \\exp(-(U(j)-U(i))/kT))\\) Temperature appears in the denominator of the exponent. At high temperatures, the simulation readily accepts moves to higher energy states. At low temperatures, it rejects most uphill moves. This creates a trade-off: low temperatures accurately reflect the system’s stable states but can trap simulations in local minima. High temperatures explore configuration space efficiently but may not emphasize physically relevant states appropriately. The butane example illustrates this perfectly. At very low temperatures, a simulation starting in the anti conformation would rarely sample the gauche states. At room temperature, transitions between conformations occur regularly, allowing proper sampling. At very high temperatures, the simulation would sample all dihedral angles almost equally, failing to capture the natural preferences of the molecule. 2.1.10 Practical Considerations While the Metropolis algorithm is conceptually simple, several practical considerations affect its efficiency in real simulations. 2.1.10.1 Move Selection The way we propose new configurations significantly impacts sampling efficiency. Different types of moves are appropriate for different systems: For atomic systems, simple displacements work well. We randomly select an atom and move it by a small amount in a random direction. For molecular systems, we often need more sophisticated moves. Rotating around bonds (changing dihedral angles) is particularly effective for organic molecules. For systems with multiple molecules, we might translate or rotate entire molecules as a unit. 2.1.10.2 Step Size Tuning The magnitude of the proposed moves—the “step size”—is crucial for efficient sampling. If steps are too small, the simulation explores configuration space very slowly. If steps are too large, most moves will be rejected because they create high-energy configurations with atomic overlaps. As a rule of thumb, aim for an acceptance rate around 40-50%. During the simulation setup, you can adjust the step size to achieve this target. Some advanced simulations dynamically adjust the step size as the simulation progresses. 2.1.10.3 Equilibration Period When we start a simulation, our initial configuration might be far from typical equilibrium structures. To avoid biasing our results, we discard data from an initial “equilibration” phase before collecting statistics. The length of this phase depends on the system, but it should be long enough that the simulation no longer shows any memory of the initial configuration. 2.1.10.4 Correlated Samples Unlike the uniform Monte Carlo methods in Lecture 1, successive configurations in a Metropolis simulation are correlated. Each new configuration is generated from the previous one, so they’re not independent samples. This correlation affects uncertainty estimates. When calculating statistical errors, we must account for correlation between samples. A common approach is “block averaging,” where we divide the simulation into blocks, calculate averages within each block, and then analyze the variance between block averages. 2.1.11 Example: Conformational Sampling of Butane Let’s apply the Metropolis method to a simple but illustrative chemical example: the conformational preferences of butane (C4H10). Butane serves as an excellent model system for studying conformational energetics. The rotation around its central carbon-carbon bond gives rise to three main conformations: the “anti” (φ = 180°) and two equivalent “gauche” conformations (φ ≈ ±60°). The potential energy as a function of this dihedral angle can be approximated by: \\(U(\\phi) = A_0 + A_1(1+\\cos\\phi) + A_2(1-\\cos2\\phi) + A_3(1+\\cos3\\phi)\\) For this system, a simple Metropolis Monte Carlo simulation would involve: 1. Starting with an initial dihedral angle, perhaps 180° (anti) 2. Proposing small random changes to this angle 3. Accepting or rejecting according to the Metropolis criterion 4. Recording the dihedral angles visited during the simulation After sufficient sampling, a histogram of dihedral angles would show peaks at 180° (anti) and ±60° (gauche). This illustrates an important concept in chemical systems: the balance between energy and entropy. The anti conformation is energetically favored, but there are two equivalent gauche conformations, creating an entropic preference for the gauche state. 2.1.12 Comparison with Molecular Dynamics Having examined Metropolis Monte Carlo, it’s instructive to compare it with Molecular Dynamics (MD) approaches. Each method has distinct advantages for different applications: Molecular Dynamics: - Follows physically realistic trajectories based on Newton’s equations - Provides time-dependent properties and kinetic information - Requires force calculations (energy derivatives) - Limited by time step constraints - May struggle with rare events separated by high energy barriers Metropolis Monte Carlo: - Makes non-physical transitions between states - Directly samples from the Boltzmann distribution - Requires only energy differences, not forces - Has no time step constraints - Cannot provide dynamical information in its standard form - Often more efficient for sampling across energy barriers While the Metropolis algorithm focuses on equilibrium properties and lacks time information, specialized Monte Carlo variants (such as Kinetic Monte Carlo) can model time evolution and dynamical processes. This makes the Monte Carlo approach more versatile than it might initially appear. When to Choose Which Method: MD is often preferable when: - Dynamical information (time-correlation functions, diffusion rates) is needed - The system’s kinetic behavior is of primary interest - Realistic trajectories are important for understanding mechanism MC is often preferable when: - Only equilibrium properties are of interest - The system has high energy barriers that trap MD in metastable states - The system has discrete degrees of freedom - Force calculations are expensive or difficult - Specialized sampling of specific degrees of freedom is needed In practice, many computational studies use both approaches, sometimes in combination. Hybrid Monte Carlo methods incorporate elements of both MD and MC to leverage their complementary strengths. 2.1.13 Summary and Preview In this lecture, we’ve expanded our Monte Carlo toolkit to address the challenges of chemical systems. We’ve seen why the Boltzmann distribution requires specialized sampling techniques, and how the Metropolis algorithm provides an elegant solution through Markov Chain Monte Carlo. The key concepts we’ve covered include: The distinction between uniform and Boltzmann-weighted sampling The challenges posed by the partition function and high dimensionality How Markov chains can generate samples from a target distribution The principle of detailed balance and its role in ensuring correct sampling The Metropolis acceptance criterion and its implementation Practical considerations for effective Monte Carlo simulations Comparison of Monte Carlo with Molecular Dynamics approaches In our next lecture, we’ll take Monte Carlo in a new direction by incorporating time evolution. While the Metropolis algorithm focuses on equilibrium properties, Kinetic Monte Carlo methods allow us to simulate the dynamic evolution of systems over time. This will enable us to study processes like chemical reactions and diffusion using a Monte Carlo framework, opening the door to phenomena occurring on longer timescales than are accessible with traditional molecular dynamics. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
